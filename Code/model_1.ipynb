{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-81</td>\n",
       "      <td>0.11600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.60</td>\n",
       "      <td>76.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-176</td>\n",
       "      <td>0.03410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.46</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>-174</td>\n",
       "      <td>0.00537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-211</td>\n",
       "      <td>0.04200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>40.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-232</td>\n",
       "      <td>0.06730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.63400</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-152</td>\n",
       "      <td>0.63400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.35</td>\n",
       "      <td>453.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01740</td>\n",
       "      <td>-2.57</td>\n",
       "      <td>-166</td>\n",
       "      <td>0.01740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.22900</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-220</td>\n",
       "      <td>0.22900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.16200</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-236</td>\n",
       "      <td>0.16200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.28300</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-225</td>\n",
       "      <td>0.28300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_disposition  koi_fpflag_co  koi_fpflag_nt  koi_fpflag_ss  koi_prad  \\\n",
       "0          CONFIRMED              0              0              0      2.83   \n",
       "1     FALSE POSITIVE              0              0              1     14.60   \n",
       "2     FALSE POSITIVE              0              0              1     33.46   \n",
       "3          CONFIRMED              0              0              0      2.75   \n",
       "4          CONFIRMED              0              0              0      2.77   \n",
       "...              ...            ...            ...            ...       ...   \n",
       "6986  FALSE POSITIVE              0              0              0      1.11   \n",
       "6987  FALSE POSITIVE              1              0              1     29.35   \n",
       "6988       CANDIDATE              0              0              0      0.72   \n",
       "6989  FALSE POSITIVE              1              0              0      1.07   \n",
       "6990  FALSE POSITIVE              1              0              0      1.05   \n",
       "\n",
       "      koi_model_snr  koi_fpflag_ec  koi_duration_err2  koi_prad_err2  \\\n",
       "0              25.8              0           -0.11600          -0.19   \n",
       "1              76.3              0           -0.03410          -1.31   \n",
       "2             505.6              0           -0.00537          -2.83   \n",
       "3              40.9              0           -0.04200          -0.35   \n",
       "4              40.2              0           -0.06730          -0.30   \n",
       "...             ...            ...                ...            ...   \n",
       "6986            8.4              1           -0.63400          -0.23   \n",
       "6987          453.3              0           -0.01740          -2.57   \n",
       "6988           10.6              0           -0.22900          -0.08   \n",
       "6989           12.3              0           -0.16200          -0.11   \n",
       "6990            8.2              1           -0.28300          -0.12   \n",
       "\n",
       "      koi_steff_err2  koi_duration_err1  \n",
       "0                -81            0.11600  \n",
       "1               -176            0.03410  \n",
       "2               -174            0.00537  \n",
       "3               -211            0.04200  \n",
       "4               -232            0.06730  \n",
       "...              ...                ...  \n",
       "6986            -152            0.63400  \n",
       "6987            -166            0.01740  \n",
       "6988            -220            0.22900  \n",
       "6989            -236            0.16200  \n",
       "6990            -225            0.28300  \n",
       "\n",
       "[6991 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making you dataframe based on sorted features\n",
    "sorted_df=df[['koi_disposition','koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
    "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
    "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
    "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
    "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
    "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
    "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
    "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
    "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
    "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
    "       'koi_kepmag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new features based on sorted features\n",
    "X1 = df[['koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1= sorted_df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768901</td>\n",
       "      <td>7.380000e-05</td>\n",
       "      <td>-7.380000e-05</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>...</td>\n",
       "      <td>-171</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733726</td>\n",
       "      <td>6.060000e-06</td>\n",
       "      <td>-6.060000e-06</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>...</td>\n",
       "      <td>-175</td>\n",
       "      <td>4.578</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652707</td>\n",
       "      <td>6.540000e-05</td>\n",
       "      <td>-6.540000e-05</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>...</td>\n",
       "      <td>-189</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.953547</td>\n",
       "      <td>1.910000e-05</td>\n",
       "      <td>-1.910000e-05</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>4.536</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959319</td>\n",
       "      <td>5.150000e-07</td>\n",
       "      <td>-5.150000e-07</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>-77</td>\n",
       "      <td>4.359</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "6122              0              0              0              0    6.768901   \n",
       "6370              0              1              0              1    0.733726   \n",
       "2879              1              0              0              0    7.652707   \n",
       "107               0              0              0              0    7.953547   \n",
       "29                0              0              0              0    4.959319   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "6122     7.380000e-05    -7.380000e-05   133.077240          0.008440   \n",
       "6370     6.060000e-06    -6.060000e-06   132.020050          0.007950   \n",
       "2879     6.540000e-05    -6.540000e-05   134.460380          0.006190   \n",
       "107      1.910000e-05    -1.910000e-05   174.662240          0.001820   \n",
       "29       5.150000e-07    -5.150000e-07   172.258529          0.000083   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "6122         -0.008440  ...            -171      4.327           0.153   \n",
       "6370         -0.007950  ...            -175      4.578           0.033   \n",
       "2879         -0.006190  ...            -189      4.481           0.050   \n",
       "107          -0.001820  ...             -85      4.536           0.056   \n",
       "29           -0.000083  ...             -77      4.359           0.110   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "6122          -0.187     1.125          0.310         -0.207  294.40472   \n",
       "6370          -0.187     0.797          0.211         -0.056  284.50391   \n",
       "2879          -0.200     0.963          0.290         -0.097  295.50211   \n",
       "107           -0.016     0.779          0.023         -0.049  291.15878   \n",
       "29            -0.110     1.082          0.173         -0.130  292.16705   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "6122  39.351681      14.725  \n",
       "6370  42.463860      15.770  \n",
       "2879  38.983540      13.099  \n",
       "107   40.750271      15.660  \n",
       "29    48.727589      15.263  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3060</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-171</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2820</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-175</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>254.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-189</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0595</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-85</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>696.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-77</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_co  koi_fpflag_nt  koi_fpflag_ss  koi_prad  koi_model_snr  \\\n",
       "6122              0              0              0      1.24           10.8   \n",
       "6370              0              0              1      0.86           13.8   \n",
       "2879              0              1              0      3.21          254.3   \n",
       "107               0              0              0      2.25           38.4   \n",
       "29                0              0              0     12.21          696.5   \n",
       "\n",
       "      koi_fpflag_ec  koi_duration_err2  koi_prad_err2  koi_steff_err2  \\\n",
       "6122              0            -0.3060          -0.23            -171   \n",
       "6370              1            -0.2820          -0.06            -175   \n",
       "2879              0             0.0000          -0.32            -189   \n",
       "107               0            -0.0595          -0.14             -85   \n",
       "29                0            -0.0075          -1.46             -77   \n",
       "\n",
       "      koi_duration_err1  \n",
       "6122             0.3060  \n",
       "6370             0.2820  \n",
       "2879             0.0000  \n",
       "107              0.0595  \n",
       "29               0.0075  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale  new data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler1 = MinMaxScaler().fit(X_train1)\n",
    "X_train_scaled1 = X_scaler1.transform(X_train1)\n",
    "X_test_scaled1 = X_scaler1.transform(X_test1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model with SVC(different kernels)\n",
    "\n",
    "## 1. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8455082967766546\n",
      "Testing Data Score: 0.8415331807780321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model1 = SVC(kernel='linear')\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {model1.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model1.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8176616440968911\n",
      "Testing Data Score: 0.8203661327231121\n"
     ]
    }
   ],
   "source": [
    "#Testing linear model with sorted features\n",
    "from sklearn.svm import SVC \n",
    "tuned_model1 = SVC(kernel='linear')\n",
    "tuned_model1.fit(X_train_scaled1, y_train1)\n",
    "print(f\"Training Data Score: {tuned_model1.score(X_train_scaled1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {tuned_model1.score(X_test_scaled1, y_test1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.831012778943353\n",
      "Testing Data Score: 0.8255148741418764\n"
     ]
    }
   ],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "model2 = SVC(kernel='rbf')\n",
    "model2.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8148006866297921\n",
      "Testing Data Score: 0.8192219679633868\n"
     ]
    }
   ],
   "source": [
    "#Testing RBF model with sorted features\n",
    "from sklearn.svm import SVC \n",
    "tuned_model2 = SVC(kernel='rbf')\n",
    "tuned_model2.fit(X_train_scaled1,y_train1)\n",
    "print(f\"Training Data Score: {tuned_model2.score(X_train_scaled1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {tuned_model2.score(X_test_scaled1, y_test1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.846271218767881\n",
      "Testing Data Score: 0.8386727688787186\n"
     ]
    }
   ],
   "source": [
    "model3 = SVC(kernel='poly')\n",
    "model3.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model3.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model3.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8394049208468434\n",
      "Testing Data Score: 0.830091533180778\n"
     ]
    }
   ],
   "source": [
    "#Testing Poly model with sorted features\n",
    "tuned_model3 = SVC(kernel='poly')\n",
    "tuned_model3.fit(X_train_scaled1,y_train1)\n",
    "print(f\"Training Data Score: {tuned_model3.score(X_train_scaled1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {tuned_model3.score(X_test_scaled1, y_test1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564073226544623"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "model4 = clf.fit(X_train, y_train)\n",
    "model4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495423340961098"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing Decision Tree model with sorted features\n",
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "sorted_model4 = clf1.fit(X_train1, y_train1)\n",
    "sorted_model4.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "model5 = rf.fit(X_train, y_train)\n",
    "model5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953089244851259"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing RandomForest model with sorted features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1 = RandomForestClassifier(n_estimators=100)\n",
    "sorted_model5 = rf1.fit(X_train1, y_train1)\n",
    "sorted_model5.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.617776082395575\n",
      "Testing Data Score: 0.5909610983981693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model6 = LogisticRegression()\n",
    "model6.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {model6.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model6.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8603852756055693\n",
      "Testing Data Score: 0.851258581235698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Testing LogisticRegression model with sorted features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sorted_model6 = LogisticRegression()\n",
    "sorted_model6.fit(X_train1, y_train1)\n",
    "print(f\"Training Data Score: {sorted_model6.score(X_train1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {sorted_model6.score(X_test1, y_test1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.790\n",
      "k: 3, Train/Test Score: 0.897/0.811\n",
      "k: 5, Train/Test Score: 0.878/0.820\n",
      "k: 7, Train/Test Score: 0.866/0.823\n",
      "k: 9, Train/Test Score: 0.856/0.828\n",
      "k: 11, Train/Test Score: 0.848/0.828\n",
      "k: 13, Train/Test Score: 0.849/0.822\n",
      "k: 15, Train/Test Score: 0.841/0.824\n",
      "k: 17, Train/Test Score: 0.838/0.827\n",
      "k: 19, Train/Test Score: 0.836/0.824\n",
      "k: 21, Train/Test Score: 0.839/0.823\n",
      "k: 23, Train/Test Score: 0.840/0.826\n",
      "k: 25, Train/Test Score: 0.837/0.824\n",
      "k: 27, Train/Test Score: 0.836/0.822\n",
      "k: 29, Train/Test Score: 0.835/0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize\n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.824\n",
      "k: 3, Train/Test Score: 0.912/0.840\n",
      "k: 5, Train/Test Score: 0.892/0.843\n",
      "k: 7, Train/Test Score: 0.885/0.848\n",
      "k: 9, Train/Test Score: 0.884/0.847\n",
      "k: 11, Train/Test Score: 0.882/0.852\n",
      "k: 13, Train/Test Score: 0.878/0.848\n",
      "k: 15, Train/Test Score: 0.878/0.850\n",
      "k: 17, Train/Test Score: 0.874/0.844\n",
      "k: 19, Train/Test Score: 0.874/0.850\n",
      "k: 21, Train/Test Score: 0.872/0.848\n",
      "k: 23, Train/Test Score: 0.872/0.853\n",
      "k: 25, Train/Test Score: 0.872/0.852\n",
      "k: 27, Train/Test Score: 0.871/0.850\n",
      "k: 29, Train/Test Score: 0.872/0.851\n"
     ]
    }
   ],
   "source": [
    "#Testing KNN model with sorted features\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores1 = []\n",
    "test_scores1 = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled1, y_train1)\n",
    "    train_score1 = knn.score(X_train_scaled1, y_train1)\n",
    "    test_score1 = knn.score(X_test_scaled1, y_test1)\n",
    "    train_scores1.append(train_score1)\n",
    "    test_scores1.append(test_score1)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score1:.3f}/{test_score1:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize based on sorted features\n",
    "plt.plot(range(1, 30, 2), train_scores1, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores1, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.title(\"Testing Accuracy Score Based on Sorted Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'min_samples_split': [1, 2, 3],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "grid = GridSearchCV(model5, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.904, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.903, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.892, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.878, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.886, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.901, total=   2.1s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.906, total=   2.1s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.881, total=   2.1s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.881, total=   2.0s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.882, total=   2.0s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.905, total=   3.2s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.908, total=   3.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.883, total=   3.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.882, total=   3.1s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.886, total=   3.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.904, total=   1.0s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.903, total=   1.0s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.888, total=   1.0s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.883, total=   1.0s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.880, total=   1.0s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.905, total=   2.1s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.906, total=   2.1s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.880, total=   2.1s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.879, total=   2.0s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.880, total=   2.1s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.907, total=   3.1s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.909, total=   3.1s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.887, total=   3.1s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.886, total=   3.0s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.877, total=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model using sorted features\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid1 = {'min_samples_split': [1, 2, 3],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "grid1 = GridSearchCV(sorted_model5, param_grid1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.902, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.895, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.892, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.870, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.872, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.902, total=   0.9s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.904, total=   0.9s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.894, total=   0.9s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.867, total=   0.8s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.874, total=   0.9s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.903, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.893, total=   1.4s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.892, total=   1.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.872, total=   1.4s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.875, total=   1.4s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.901, total=   0.5s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.902, total=   0.4s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.892, total=   0.5s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.871, total=   0.4s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.876, total=   0.4s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.903, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.897, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.891, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.867, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.872, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.902, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.901, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.888, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.866, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.876, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   27.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch using sorted features\n",
    "grid1.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 3, 'n_estimators': 300}\n",
      "0.8931865317023119\n",
      "{'min_samples_split': 3, 'n_estimators': 100}\n",
      "0.8884169947387187\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid1.best_params_)\n",
    "print(grid1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.901\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)\n",
    "print('Test Acc: %.3f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.897\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model and sorted features\n",
    "predictions1 = grid1.predict(X_test1)\n",
    "print('Test Acc: %.3f' % grid1.score(X_test1, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.83      0.76      0.79       411\n",
      "FALSE POSITIVE       0.84      0.85      0.84       484\n",
      "     CONFIRMED       0.97      1.00      0.98       853\n",
      "\n",
      "      accuracy                           0.90      1748\n",
      "     macro avg       0.88      0.87      0.87      1748\n",
      "  weighted avg       0.90      0.90      0.90      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CANDIDATE\",\"FALSE POSITIVE\",\"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.75      0.78       411\n",
      "FALSE POSITIVE       0.81      0.85      0.83       484\n",
      "     CONFIRMED       0.98      1.00      0.99       853\n",
      "\n",
      "      accuracy                           0.90      1748\n",
      "     macro avg       0.87      0.86      0.87      1748\n",
      "  weighted avg       0.90      0.90      0.90      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report with sorted features\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, predictions1,\n",
    "                            target_names=[\"CANDIDATE\",\"FALSE POSITIVE\",\"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1089200886632165, 'koi_fpflag_co'),\n",
       " (0.10078237184697997, 'koi_fpflag_nt'),\n",
       " (0.060494727431928685, 'koi_model_snr'),\n",
       " (0.0597118448074922, 'koi_fpflag_ss'),\n",
       " (0.05113899048828299, 'koi_prad'),\n",
       " (0.03616025679004334, 'koi_fpflag_ec'),\n",
       " (0.03445962703194788, 'koi_steff_err1'),\n",
       " (0.033565482481020606, 'koi_duration_err1'),\n",
       " (0.03289085110256796, 'koi_prad_err1'),\n",
       " (0.03084788266945217, 'koi_duration_err2')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can weight the features by their importance for more tuning purpose\n",
    "sorted_features=sorted(zip(model5.feature_importances_, X.columns), reverse=True)[:10]\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Importance Level')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Can be visualized in bar graph for analysis reason (feature weight)\n",
    "ax=pd.DataFrame(sorted_features).plot.bar(x=1,y=0, rot=45, title=\"Feature Importance\")\n",
    "ax.set_xlabel(\"Features Name\")\n",
    "ax.set_ylabel(\"Importance Level\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerunning Models by using top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new features based on sorted features\n",
    "X1 = df[['koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'SVM.sav'\n",
    "joblib.dump(sorted_model5, 'SVM.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Training Score with Sorted Features</th>\n",
       "      <th>Testing Score with Sorted Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.8455082967766546</td>\n",
       "      <td>0.8415331807780321</td>\n",
       "      <td>0.8176616440968911</td>\n",
       "      <td>0.8203661327231121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.831012778943353</td>\n",
       "      <td>0.8255148741418764</td>\n",
       "      <td>0.8148006866297921</td>\n",
       "      <td>0.8192219679633868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poly</td>\n",
       "      <td>0.846271218767881</td>\n",
       "      <td>0.8386727688787186</td>\n",
       "      <td>0.8394049208468434</td>\n",
       "      <td>0.830091533180778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decison Tree</td>\n",
       "      <td>0.8501144164759725</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.8506864988558352</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8958810068649885</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.8953089244851259</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.617776082395575</td>\n",
       "      <td>0.5909610983981693</td>\n",
       "      <td>0.8603852756055693</td>\n",
       "      <td>0.851258581235698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name      Training Score       Testing Score  \\\n",
       "0               Linear  0.8455082967766546  0.8415331807780321   \n",
       "1                  RBF   0.831012778943353  0.8255148741418764   \n",
       "2                 Poly   0.846271218767881  0.8386727688787186   \n",
       "3         Decison Tree  0.8501144164759725                 N/A   \n",
       "4        Random Forest  0.8958810068649885                 N/A   \n",
       "5  Logistic Regression   0.617776082395575  0.5909610983981693   \n",
       "6                  KNN               0.845               0.824   \n",
       "\n",
       "  Training Score with Sorted Features Testing Score with Sorted Features  \n",
       "0                  0.8176616440968911                 0.8203661327231121  \n",
       "1                  0.8148006866297921                 0.8192219679633868  \n",
       "2                  0.8394049208468434                  0.830091533180778  \n",
       "3                  0.8506864988558352                                N/A  \n",
       "4                  0.8953089244851259                                N/A  \n",
       "5                  0.8603852756055693                  0.851258581235698  \n",
       "6                               0.872                              0.851  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying all results in table\n",
    "import numpy as np\n",
    "score_summary_df = pd.DataFrame(np.array([[\"Linear\", 0.8455082967766546, 0.8415331807780321, 0.8176616440968911, 0.8203661327231121],\n",
    "                                          [\"RBF\", 0.831012778943353, 0.8255148741418764, 0.8148006866297921, 0.8192219679633868],\n",
    "                                          [\"Poly\", 0.846271218767881, 0.8386727688787186, 0.8394049208468434, 0.830091533180778],\n",
    "                                          [\"Decison Tree\", 0.8501144164759725, \"N/A\", 0.8506864988558352, \"N/A\"],\n",
    "                                          [\"Random Forest\",0.8958810068649885, \"N/A\", 0.8953089244851259, \"N/A\"],\n",
    "                                          [\"Logistic Regression\", 0.617776082395575, 0.5909610983981693, 0.8603852756055693, 0.851258581235698],\n",
    "                                          [\"KNN\", 0.845, 0.824, 0.872, 0.851] ]),                 \n",
    "                   columns=['Model Name', 'Training Score', 'Testing Score','Training Score with Sorted Features', 'Testing Score with Sorted Features'])\n",
    "score_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
