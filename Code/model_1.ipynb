{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
    "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
    "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
    "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
    "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
    "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
    "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
    "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
    "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
    "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
    "       'koi_kepmag']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768901</td>\n",
       "      <td>7.380000e-05</td>\n",
       "      <td>-7.380000e-05</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>...</td>\n",
       "      <td>-171</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733726</td>\n",
       "      <td>6.060000e-06</td>\n",
       "      <td>-6.060000e-06</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>...</td>\n",
       "      <td>-175</td>\n",
       "      <td>4.578</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652707</td>\n",
       "      <td>6.540000e-05</td>\n",
       "      <td>-6.540000e-05</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>...</td>\n",
       "      <td>-189</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.953547</td>\n",
       "      <td>1.910000e-05</td>\n",
       "      <td>-1.910000e-05</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>4.536</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959319</td>\n",
       "      <td>5.150000e-07</td>\n",
       "      <td>-5.150000e-07</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>-77</td>\n",
       "      <td>4.359</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "6122              0              0              0              0    6.768901   \n",
       "6370              0              1              0              1    0.733726   \n",
       "2879              1              0              0              0    7.652707   \n",
       "107               0              0              0              0    7.953547   \n",
       "29                0              0              0              0    4.959319   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "6122     7.380000e-05    -7.380000e-05   133.077240          0.008440   \n",
       "6370     6.060000e-06    -6.060000e-06   132.020050          0.007950   \n",
       "2879     6.540000e-05    -6.540000e-05   134.460380          0.006190   \n",
       "107      1.910000e-05    -1.910000e-05   174.662240          0.001820   \n",
       "29       5.150000e-07    -5.150000e-07   172.258529          0.000083   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "6122         -0.008440  ...            -171      4.327           0.153   \n",
       "6370         -0.007950  ...            -175      4.578           0.033   \n",
       "2879         -0.006190  ...            -189      4.481           0.050   \n",
       "107          -0.001820  ...             -85      4.536           0.056   \n",
       "29           -0.000083  ...             -77      4.359           0.110   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "6122          -0.187     1.125          0.310         -0.207  294.40472   \n",
       "6370          -0.187     0.797          0.211         -0.056  284.50391   \n",
       "2879          -0.200     0.963          0.290         -0.097  295.50211   \n",
       "107           -0.016     0.779          0.023         -0.049  291.15878   \n",
       "29            -0.110     1.082          0.173         -0.130  292.16705   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "6122  39.351681      14.725  \n",
       "6370  42.463860      15.770  \n",
       "2879  38.983540      13.099  \n",
       "107   40.750271      15.660  \n",
       "29    48.727589      15.263  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 40)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler1 = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled1 = X_scaler1.transform(X_train)\n",
    "X_test_scaled1 = X_scaler1.transform(X_test)\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model with SVC(different kernels)\n",
    "\n",
    "## 1. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8922372687392714\n",
      "Testing Data Score: 0.8884439359267735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model1 = SVC(kernel='linear')\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {model1.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model1.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.889567041769979\n",
      "Testing Data Score: 0.8752860411899314\n"
     ]
    }
   ],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "model2 = SVC(kernel='rbf')\n",
    "model2.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8163265306122449\n",
      "Testing Data Score: 0.8146453089244852\n"
     ]
    }
   ],
   "source": [
    "model3 = SVC(kernel='poly')\n",
    "model3.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model3.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model3.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847254004576659"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "model4 = clf.fit(X_train, y_train)\n",
    "model4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010297482837528"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "model5 = rf.fit(X_train, y_train)\n",
    "model5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10941997603323719, 'koi_fpflag_co'),\n",
       " (0.09698826670689385, 'koi_fpflag_nt'),\n",
       " (0.0662217887574338, 'koi_fpflag_ss'),\n",
       " (0.053738030601233645, 'koi_model_snr'),\n",
       " (0.049883533336831126, 'koi_prad'),\n",
       " (0.03945186888603084, 'koi_fpflag_ec'),\n",
       " (0.03563932126179036, 'koi_prad_err1'),\n",
       " (0.034488446004718905, 'koi_duration_err2'),\n",
       " (0.029929936615739807, 'koi_prad_err2'),\n",
       " (0.029783090045493146, 'koi_duration_err1')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance\n",
    "sorted_features=sorted(zip(model5.feature_importances_, X.columns), reverse=True)[:10]\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa7a35436d0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAFCCAYAAADi2+qOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdVXn/8c+TSUKAAEkh3DKhSUgEA4jGEMKdBoQkQCJeMCjKD6yRNoCIv7ZoS70hYkuloJQYEZRqpYqiUQKI4v1ngKA2SikaAc0g1kh/IsgrBsLTP551mO3hzMyambPP3pN836/Xec2cffY5+zlr9uxnr7XXXsvcHRERkYGMqjoAEREZGZQwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLKMrjqAVnbbbTefOnVq1WGIiIwY995772/cfVKZ26hlwpg6dSpr166tOgwRkRHDzH5e9jbUJCUiIlmUMEREJIsShoiIZKnlNQwRkSo8/fTT9PT0sGnTpqpD6dO4cePo7u5mzJgxHd+2EoaISNLT08NOO+3E1KlTMbOqw3ked+exxx6jp6eHadOmdXz7apISEUk2bdrErrvuWstkAWBm7LrrrpXVgJQwREQK6posGqqMTwlDRKRmbrvtNvbbbz9mzJjBZZddVnU4zxmR1zCmXnTLsD/j4ctOakMkIrI1a8expijnuLNlyxaWL1/OHXfcQXd3N4cccgiLFy9m1qxZbY1lKFTDEBGpkbvvvpsZM2Ywffp0xo4dy9KlS/niF79YdViAEoaISK088sgjTJky5bnn3d3dPPLIIxVG1EsJQ0SkRtz9ecvqciFeCUNEpEa6u7vZsGHDc897enrYe++9K4yolxKGiEiNHHLIIfz0pz/loYceYvPmzdx4440sXry46rCAEdpLSkRkazV69Gg+/OEPc+KJJ7JlyxbOPvtsDjjggKrDApQwRET6VFX3+0WLFrFo0aJKtt0fNUmJiEgWJQwREcmihCEiIlmUMEREClrdB1EnVcanhCEikowbN47HHnustkmjMR/GuHHjKtm+ekmJiCTd3d309PSwcePGqkPpU2PGvSpkJQwzWwBcCXQB17r7ZU2v7w9cD8wG/tbdL899r4hIXYwZM6aSmexGigGbpMysC7gaWAjMAk43s+Zxdv8HOB+4fAjvFRGRESDnGsZcYL27P+jum4EbgSXFFdz91+5+D/D0YN8rIiIjQ07CmAxsKDzvSctyDOe9IiJSIzkJo9W4urldCLLfa2bLzGytma2t8wUnEZFtVU7C6AGmFJ53A7/M/Pzs97r7Snef4+5zJk2alPnxIiLSKTkJ4x5gpplNM7OxwFJgVebnD+e9IiJSIwN2q3X3Z8zsXOB2omvsde5+n5mdk15fYWZ7AmuBnYFnzewCYJa7/67Ve8v6MiIiUp6s+zDcfTWwumnZisLvvyKam7LeKyIiI4+GBhERkSwaGmSIpl50y7A/o6rJWUREhkI1DBERyaKEISIiWZQwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkS1bCMLMFZvaAma03s4tavG5mdlV6fZ2ZzS689lYzu8/Mfmxmnzazce38AiIi0hkDJgwz6wKuBhYCs4DTzWxW02oLgZnpsQy4Jr13MnA+MMfdDwS6gKVti15ERDomp4YxF1jv7g+6+2bgRmBJ0zpLgBs8rAEmmNle6bXRwPZmNhrYAfhlm2IXEZEOykkYk4ENhec9admA67j7I8DlwC+AR4HH3f0rQw9XRESqkpMwrMUyz1nHzCYStY9pwN7AjmZ2RsuNmC0zs7Vmtnbjxo0ZYYmISCflJIweYErheTfPb1bqa53jgYfcfaO7Pw18Hji81UbcfaW7z3H3OZMmTcqNX0REOiQnYdwDzDSzaWY2lrhovappnVXAG1JvqXlE09OjRFPUPDPbwcwMOA64v43xi4hIh4weaAV3f8bMzgVuJ3o5Xefu95nZOen1FcBqYBGwHngKOCu9dpeZ3QR8H3gG+AGwsowvIiIi5RowYQC4+2oiKRSXrSj87sDyPt77TuCdw4hRRERqQHd6i4hIFiUMERHJooQhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIFiUMERHJooQhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIFiUMERHJooQhIiJZlDBERCSLEoaIiGQZXXUAMjxTL7pl2J/x8GUntSESEdnaqYYhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIlqyEYWYLzOwBM1tvZhe1eN3M7Kr0+jozm114bYKZ3WRm/2Vm95vZYe38AiIi0hkDJgwz6wKuBhYCs4DTzWxW02oLgZnpsQy4pvDalcBt7r4/cDBwfxviFhGRDsupYcwF1rv7g+6+GbgRWNK0zhLgBg9rgAlmtpeZ7QwcDXwMwN03u/tv2xi/iIh0SE7CmAxsKDzvScty1pkObASuN7MfmNm1ZrbjMOIVEZGK5CQMa7HMM9cZDcwGrnH3lwC/B553DQTAzJaZ2VozW7tx48aMsEREpJNyEkYPMKXwvBv4ZeY6PUCPu9+Vlt9EJJDncfeV7j7H3edMmjQpJ3YREemgnIRxDzDTzKaZ2VhgKbCqaZ1VwBtSb6l5wOPu/qi7/wrYYGb7pfWOA/6zXcGLiEjnDDi8ubs/Y2bnArcDXcB17n6fmZ2TXl8BrAYWAeuBp4CzCh9xHvCplGwebHpNRERGiKz5MNx9NZEUistWFH53YHkf7/0hMGcYMYqISA3oTm8REcmihCEiIlmUMEREJIsShoiIZFHCEBGRLEoYIiKSRQlDRESyZN2HIdKfqRfdMuzPePiyk9oQiYiUSTUMERHJooQhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkXdamWroe69IuVSDUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkixKGiIhkyUoYZrbAzB4ws/VmdlGL183MrkqvrzOz2U2vd5nZD8zsy+0KXEREOmvAhGFmXcDVwEJgFnC6mc1qWm0hMDM9lgHXNL3+FuD+YUcrIiKVyalhzAXWu/uD7r4ZuBFY0rTOEuAGD2uACWa2F4CZdQMnAde2MW4REemwnIQxGdhQeN6TluWu88/AXwPPDjFGERGpgZyEYS2Wec46ZnYy8Gt3v3fAjZgtM7O1ZrZ248aNGWGJiEgn5czp3QNMKTzvBn6Zuc6rgMVmtggYB+xsZp909zOaN+LuK4GVAHPmzGlOSCIjguYVl61ZTg3jHmCmmU0zs7HAUmBV0zqrgDek3lLzgMfd/VF3f7u7d7v71PS+O1slCxERqb8Baxju/oyZnQvcDnQB17n7fWZ2Tnp9BbAaWASsB54CziovZBERqUJOkxTuvppICsVlKwq/O7B8gM/4BvCNQUcoIiK1oDu9RUQkixKGiIhkUcIQEZEsWdcwRGRkUfdeKYNqGCIikkU1DBEphWo5Wx/VMEREJIsShoiIZFHCEBGRLEoYIiKSRQlDRESyKGGIiEgWJQwREcmihCEiIll0456IbNXqcANhHWJoB9UwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkixKGiIhkUcIQEZEsShgiIpJFCUNERLIoYYiISJashGFmC8zsATNbb2YXtXjdzOyq9Po6M5udlk8xs6+b2f1mdp+ZvaXdX0BERDpjwIRhZl3A1cBCYBZwupnNalptITAzPZYB16TlzwBvc/cXAvOA5S3eKyIiI0BODWMusN7dH3T3zcCNwJKmdZYAN3hYA0wws73c/VF3/z6Auz8B3A9MbmP8IiLSITkJYzKwofC8h+cf9Adcx8ymAi8B7hpskCIiUr2chGEtlvlg1jGz8cDngAvc/XctN2K2zMzWmtnajRs3ZoQlIiKdlJMweoAphefdwC9z1zGzMUSy+JS7f76vjbj7Snef4+5zJk2alBO7iIh0UE7CuAeYaWbTzGwssBRY1bTOKuANqbfUPOBxd3/UzAz4GHC/u3+wrZGLiEhHjR5oBXd/xszOBW4HuoDr3P0+Mzsnvb4CWA0sAtYDTwFnpbcfAbwe+JGZ/TAte4e7r27v1xARkbINmDAA0gF+ddOyFYXfHVje4n3fofX1DRERGWF0p7eIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIFiUMERHJooQhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIFiUMERHJooQhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIFiUMERHJooQhIiJZlDBERCSLEoaIiGRRwhARkSxKGCIikkUJQ0REsihhiIhIlqyEYWYLzOwBM1tvZhe1eN3M7Kr0+jozm537XhERGRkGTBhm1gVcDSwEZgGnm9msptUWAjPTYxlwzSDeKyIiI0BODWMusN7dH3T3zcCNwJKmdZYAN3hYA0wws70y3ysiIiNATsKYDGwoPO9Jy3LWyXmviIiMAKMz1rEWyzxznZz3xgeYLSOaswCeNLMHMmLry27Ab/pbwT4wjE9vUxx1iKEucdQhhrrEUYcY6hJHHWKoSxwZMfxpO4NpJSdh9ABTCs+7gV9mrjM2470AuPtKYGVGPAMys7XuPqcdnzXS46hDDHWJow4x1CWOOsRQlzjqEEOd4uhPTpPUPcBMM5tmZmOBpcCqpnVWAW9IvaXmAY+7+6OZ7xURkRFgwBqGuz9jZucCtwNdwHXufp+ZnZNeXwGsBhYB64GngLP6e28p30REREqV0ySFu68mkkJx2YrC7w4sz31vB7SlaasN6hBHHWKAesRRhxigHnHUIQaoRxx1iAHqE0efLI71IiIi/dPQICIikkUJQ0REsihhyKCYWat7a7YqZjY+9eqTrcy2sP+WSQljEDq9s5nZdma2e/p9jyp39sK2d6gqhqKyysLMxgOfAk4zs+3K2Ea71OHgZ2Y71iGO/qQYt4PooGNmpRz3zGwfMzvRzOaVtY3hGm5ctfxSddD4JzCzXcxsR3iuN1gnt384sNjM3gLcAvxJp7bfHEv6RzsRWJHKpNKDRIpniZmd1+bPfRL4KPA6YGGN//Ebf5OTqhoF2swOAr4PvKKuNTIz25/opfkRM/t3AHd/toTtzAJuIm4pOA94d7u3MVxm9gLgrWY2baifUct/hjpo/DMSO9u/mdlHG6914mCZktO9wCuBdwHXuPtjZW+3r1jMbAFwFXEvzeOkfaeqxJGG0H8t8MM2fmZX+vVhosv5dcDrzGxMu7bRLoUE/j7gPzq9fTPbGXgnMXLDmcAJdSsnM5sBfJaoMf4NsLOZva+E7ewBXAtc7u5Lie6xk81sl3Zva6jMbB/gLmAx8Cozmz6Uz1HC6EM6e7qE2NHOAfY1s49D+TWNxkHY3X9H7Ox3AHuY2ezGGW8nD9RpW8cR5bDGzF4J3Gpmp3ay1lWIZwJwITDN3b+dlnX1/66BufsWMzuSKPO3A+8n7i86teoaVR9OAS5291vNbDR0PIF/xN3/jDizvhA4sS41jbQ/HAOsdPeV7v7fwD9RTpPqOOBz7v6Z9HwNMdXDwSVsa6h2IxL8e4C9iCbX55JG7n6jhNG3UcA6d/+Ouz/q7vOBg8zsTWVvOJ09HmpmhwLfJppH9gZOA6ak5YvKjKHQJDeNGBNsA/BJ4oztQOCbwLvS2VXpiju0u/8W+Agw2szemZZtaVPz0QuAe919rbv/I3A5cCVwpplt34bPb4t0QNybiBd6B/Usfb6Z1Bz2O+B+AHe/gaiNXQgsSOvMqLI5z923EMMQfbGw+DfAUWY2rl3bMbNR7v5z4Ob0fLS7/4EY9eLptGyfqk843P37RPL8GvBlYHfgNWY2czCfo4SRFA6QR6aD5CZgLzM7oLDaJ4EnOhDD4cDngbcRZwTHAhcBOwLvIJrJ2t4OW5SS1mJgBTDD3a8C3gic7+7vJg4Qv6VD+1CK5zgzO9fMXpVqFsuBA83s7WmdQZdJi3/knxCJaB8z63L3m4jkeDYwfphfY8gK+8aLU3v5rkQNeKGZLU4J83Dg82b2wjJjSX+L+cDbzGxiWvZJ4OPAm8zsYmI4oErOsAt/05nAiwvLfgt0ufsmMzvWzC4d7rbc/dlUFuelZrot6aVGspgLfILexN5Rhf3mKFIyd/c7iWuiuwPzzexsYGVWUnN3PdKDOGu/D5ifnv8V8D3gDcAZxBnVn5Ucw3zgA8CLiOrzGUQTyfHEwflA4OAOlMUhRNv4C9PzHYDd0u9nAD8CXtHBv83hwENEU9GvgLen5fPSzv/3Q/jMxkgHxxITe51EDMn/ceJgvAA4kpj4a24N9s/FwN3EScRXgBOBU4EHiQv19wEndSCOF6cYjkrPRxVe+yDwB2BJxWV1APC1xv6blo0hTnSOANa2Y/9tURaNfeoDab9ZC5xccVnMai6LtPyFwBeA/w+cnvVZVX6ROj2AScRFoXlNy89KB49/A07sQBxXErWHg9PzvYgmqc8Dp3WwPF5J1KgOJmo6txAX4acSF5sXpfWsA7G8CPgQ8Kr0fHpKGn+Tnh8BzB7iZ58CrCNOCtYBf5EOLH9PnBn+v04chDPi3BP4BjCR6IXzHWBiem1yOkAeUPbfJP391xInTwcVt0ecsX6z8Hcqfd/oI8aD0v7ykcIyI2rojxPTMSwcbox9lEVX+vkuojXiuIr3m1Zl0Yjx4HSsOSm3LCr7InV7EO3B3wbGpufbNxXumA7GspJoGhmXnu8FvJ4O1CwKMewOXJ8Oom8kzqTeR6GG1akDAlGj+V7a/q5p2XRiZOS/G8bn7kE0nUwnht5fk77vO4rrdPK79hPrXkTz4JkpWcxMy1/WiLHEbTcSwuFETWYG0RHjmqb1xgNTGu+posyIC93/QFzjWk2hZghsT1ygP74DZXEUHTypGmxZpNdfCCwYzN+r41+izg/gX4meBKPT8+OIi1njG4mj5O13FX6/lmj22SE9H1tRmeySfs4B/gs4pAPbLDYVnZN+PyslsMX0nlnvO9R/fqJWcgoxwdccovltF+AE4PdEF0koNLdU/QBuIGpWMwrlc0/jecnbPpK4t2BJer4TkcSvqrpcCjHOSAfGvYiOGh8ierrNLqzTOOEYTs0iuywqTJwDlkVznDmfq4ve/NFFspVElf/LZnYGcd/Bx9z9SY9eF6XyuHDZlX7/c+Igti71Nnm67O0XFcrkD+li6qeA/+vu95S9bXd3MzsFuAb4WVp2PdEO+0rgeDOb6O4/c/evDrYHipkdCLwX+Im7bwAmALd43F/ixN/9S2m7pXYuGKRriKbJf0gXKj8MvNfd15e1wULZLgLeSpyl4+5PELWbY83smrK2nyvdZ9C4x+L37r6ZaErenpjc7ZD02v/A0LrGD6UsPBnstoYjoyyeN6tfdoxVnxXU6UHcrLUHcDFwPvCywWTfQWyncQY9ro/XizWNg0r8vv3GUVhvMoXmsHaXR4vtTSAuxu2Xnh9L1Px2JK6ffJIhNsMQbf0rSTWItOxE4OtEEnmYdB2r7O85hNi70v75t8CbSe3jZcRZ2DcmF5ZdSNzZXVy2E3B4ReVhTc9fRzQxngrsnJbtCfxLY19SWQyvLLap+TBS/3E3s3Huvmmw72tzDHOJdvMPuntPi/W6vMRaTW4cnYilj21eD+wHPAA8Q8wH7+6+yMymeNQMhvK5+xIXtHclrlWsS8tPJpqk/tvdv9qO7zCE2CrfP5s+dyHRK+07xEnFhWb2j0Rz3lJ3/0W7tzmI2BpltQCYTXRn/WfgNcQJxs3At9z9cTMb63GWPZztqSxg26lh0HuWMJfo+tfdz7qlXq8gusj+O9Ev/AukC4WtYgB2Ji5elXEWOZg4dkk7X9m1i8bfaQxRq3hpej6D6KY4pGs5wKHA0UQNYxxRy3gXcGBV+2Qf37vy/TNt42CiA8C+wBVEc+B26bUrgB80nldYZguJXkrHEEPEXJWW/2XaV5YQtbJh7bMqi8J2qvySFRRq5QfIdMC6D9ifOMv9DHGBe+8+YrgbOKyEsqg8jr4O/jRdaCYudP8QOHWQn1/s0fIQUR2/n+iWuj1xTeD9pO6oVT/qsH8WtnNYOtgcnf7209PyA9PPITdrtDHGy4kTiSXEmf/UwmvLaFOvQpVFYTtVf9EOFmjlB8j02fung0Gj99GYdDD8HPAnhfV2Ic5kjiypPCqNg+i2ezH93BBH9DDZmbgIvbixbJDbOYK4ieqY9HwKMczJGUQPkuvoQC+jkbJ/FrY1nehw8DNgQlp2PPBpUi+1qh/EPUv/CnyV3p5jrwZeo7IoqSyq/qIdLNBKDpDFA1w6AE4kbgI8DtgpLT+dqNZ+KD3fiegu2baDdF3iKMQwibij+n0McNMdhZrIEBLGh4ibtV5eWHY80fsNYMeq980q988BYlqeEtcrU5n9kIrv4G6K72jgd8Ab0/PDia7fx6gsyimLyr9oiQVY+QGS3iaRRUSV8Z3EqJGvILpt/jVR1f0q0bywKh0Q9qSNQ1HUJY5CPKPSzz2IrqH/0FfSoPeemDFDPbgTFwC/Ceyeni9J33V7KrrPoib753j6uSZE1MAaZfVR4JTm2Kt6FPbpxUTPto8SvZaGNAyHyiLvsVX2kir0GlhEjM30BHA1kYXPIu7ofpI4YF5CdJF7PXEA2cfd725jLCcRN/n8DXABMQnSK4hhBf6MuHX/H4mupJcRd17+tl3br2Ecjb/NeHd/0sx2SnE9A9zoMapmY90uj3tTJhLXHy7wGKY6d1vP9e4ys2uJs66bSRfQ3f3mNn61bHXYP613ZsHPAp/1GGG1r3VHA896DLRXSo+soSiU475Ez6Dt3P2BwcaoshiEqrNjiVn3JKLXwHHEWfR3iTPaQ4mRXz9FDHdxLDEkxIQ2bXdP4C/T72OJHi/7AS8HvkWc4d9LuihF9FxYRFyMfVEbv38t4miKqXGCsoCoxVxKDHWxA9F09D5gTlqnUQuZQAy90Oegj8T1kJb3q/DH97Rckb7fi5tf21b2z6YYTgZuTftEnzUtKjqLztluq3X6+y4qi2HGUcWXL6lAKz9AEuNRHQHcBpyblk0guuPdRZzZjgZ+nLa7Y1rnxcD+bSyLWsTRR2zHEs0shxJn1V9Ly3cn3VBHbzv+BKK9/qh+Ps+IGtNM4gy81T9NMWlck/aDjl6srMP+2VwexMjHdxB3P7+eFuOlFdbdgZLHrOoj1hOJJpZXAvsO8H1GqyyGXhZZMXT6S5dUkJUfINMBaz0xLtF8ogfFeem1PYjeOBOJZpFLgJek19rdbbcWcRTi2YNo8moMpPiqtO35RE+fP03Ld01xzUrPu4ixo47O2MYooo35SmKcn4GSxoco3KG7LeyfLWI6khh6Zg4xjP8aYoKu4rWVrkKs95QVSz8xziaa595P9Bi7hKaaZFOM/0Shg4DKYvBlMWAcnfzSJRVk5QdI4iz3TUQ30ZlEO3Rj4MLz0uufSQfARylpmPS6xNEU01uIG4dOIM6sX0PMA303vYMIvoy4brJd03vHD2I7OxMJ4wpijozmoRKeG3WYDs5PUIf9s4+4zibmZ288f1XaJ/4Phc4AROeHO8hI3G2O7wDiZrnG0NuHEfNOXEJTk2KK8RsMsUeQymIQsXTyi5dQkLU5QBJ3WP4HMZnNIWnZcURXydOJs+AZlHR9oIZxFM/OLiWGWD4mbf8qYn6NsUQXxf9kkHNO0Hs9ZDbRzDUr/b3fkz7/0MI6xX+muyjx/oUa75/NCfRIYvTbfQrlcyPRPDYpPZ9IjLFVehfeFvHuQfT0+Vph2VyiR90H6B0facJgY1RZDCOWTn/5Egqz0gNk4aA0gRji+F5iKAEjzmbnE7OjnV9yOdQijhZxzSfmEF6b4joBmEZ0df06ccaWPYFL02efTFwPuY64YPnetPzdxNwRh/HH1fSO3L9Qp/2zad84lkHMLEhMKlXqDJMtYvxTeieC2oO4D+XjhfXmAS9Iv48lOgf0eY1LZdHm2DpRACUXamUHyEIME9N2JxDV2TvpHUl0DNHk8tKtPY4WcU0hmp4a07y+E/gYqUqfYtqp+B0yPrPYtPQl4Nj0fE/iGsE5xFhRHyxsdzyRnEr9Z6rb/tkUT+1nFiQ6ANyTYrmW6FY8maiF3djHe/ZSWQy9LAYdV5WFMozCrPwAWThwLSRuCvsk0fywPTG08G3ACR0oi1rE0UdsE4mz+kMKyz6d/kkXMIjB0ChczyBmM/sgccZVnBznFOCK9PvowvIppGsD28r+2RRPLWcW5I/v4N+DSOr7Ex0A3kzcF3QAcTJwK4VaGEPsLqqyGGacndpQGwu20gMksGfh97nEWe6RxIWzS4DL0mvnpQNE23sq1CmOppgaB8rx9HaNfS8x+Nm+6flxaYd/wSA+dweiPfnM9PwA4B3EDW3rGmVBjP3/pbR+Yz/p6J3cVe+fLeKp5cyCRK+4z9I7o+TexPWlRhPMTkQTy8Xp+bBnnFRZtCHWqjY8hEKt/AAJvIC4OLlv+iOvAr5YeP1Q4gy68YeeWlJZ1CKOPmJbkuJZkw6QbyaG/7ieSB73MoSmIaKK/n2il9VB9A7f/A6iO+rfpp8Lt9X9s0VMB6ZtNSaiOh64NP3+MqKL5jFVlFeKYTpxL8rB6fl7iJEIpqXnpxEXdUcz/CHKVRbtiLOqDQ+yMGtxgCTuSr6c6JnzF+mA+HPg9YV1Pg2clX4v696GWsTRIq4DiIvQLyKanFYCbwReQrTBvgeYP4zPP4kY9O0T6fstIC5sfyJ99lGd/L512z9b/C1qN7Mgf9z0Mo44oehJB8s5RM+fW4G3pRiHXRtTWbTvMZqR4TCiStaoPv47cKmZvd7d/9Xd7w8ASaQAAAnsSURBVErT7c4lhoj+eUlx/IToGnkq8CZ3v9PMNgNvMrMpxIHiQOKMGk97wlYcR7PdgUc8ZrFbZ2aPERe5l7v754n5qIfM3W8xsy1Et9ndiHH/jyCae25x97vSep36vg112T+LNgHbAfub2YvcfZ27325mY1Kcf+7ua6Bz5ZXmpj897RdPEnPEn2xmuxJl9mriLPoEYobFM939m23YtMqiXarOWJmZ+DDiZpSfkc5QiQL9CtEkcSDwI+CIkuOYRJyVfIXoljeeqCK+lrgZ7VbSRVhKHKeoRnE0rllsV4irMeJq487uS4DTiuu3YbvziR4kx1e9b9Zp/0zbrfvMgvsAj6X9dF5h+TtIPcnata+oLNr/GPX8FFJL6wEn/iGfTaNL3kz0nT6X6EFwprt/18y6SozjCeKs/hNE2/QJRLXy34jx8p8g+tTj5c6BXYs43N3TKLhXmtk/u/tG4jrDScCFaY7hM4BfNNZv03bvJAYqvMrMpqQRRKtU6f5pqfpiZocT9w8sBW4iLra/heh18zozO6Dd2x6MNHrwL4jmuaeJmxkBcPdLiRro59IIxkPdhsqiTFVnrMxMPI7omvg64o7MV9Dbo+BUom/yaR2O6c1Ec8tpRK+cHYgz/E+T7rzc2uMg+oX/mOh58k0igU1If5MriB5CpV2EJt2FW/WjDvsnNZ5ZkN6a6N7A9un36UTT6vnp+YvTvjvsMb5UFiXGX3UAQyjw0g+Q9D9cdnHIi3OJaREb/bZ3IN2ItjXF0cf2X0rcD3FhYdmXUxyN5qhazGbXyUdVCZyazyxI9J77JnHmvJy4B+cAonb2T8CvaNOd1CqLEmOvOoCmgqz8AEnecNnFWPYpqSxqEUer7RED5f2cuKfgRxRqEcSMZLek3yuZza7E71/5/jlAfLWbWTDFcRRxX8FuxACRPyXa6UcRw8S8iTZf31FZlPOozYx7qe3xLcSgdD3AJm8Krjh7lJnt49EGWEYso4i2zouIG2q+2yKWUUSzvJc181Zd4mja3pHETWlfJIbiPosY+O9md789rfNSd7+3zDg6rU77Z4vYajmzYIpnAnGQ/G8i4V5MnEW/jbgZ80p372nj9lQWJarNRe/0j3YV0cXsMuCIxgWs4jpmNir9Y/6i+fU2xvIscecnxGQlh7bYVmNKxJ2BU8q48FqXOJosJZpddnD3J4hmqB8DZ6QpR9nakgXUY/80s93N7KAWsW1pXEx39z8nhr54BfB+d7+55I4greJsXHg+mrh+cydxR/5iYj6QzxCDUe4LQ+var7KoRm0SBlR7gCz8YWeb2bFE3+cLiB5HrwXmFtZpzDW9C9F18tfu/szWFEdf3P1couvsu81sgrs/SHTjvZe4sLjVqsH++Vpgk5lt3yJZFQ+UbyW6+X7MzCZ6uT32nid9/8OIgSDf6+6/d/dNxLztF5vZfGKcpA+4+8OD/XyVRYWqbhNj6PMarKHQd7lNsdRiuOy6xNEiruKsddem7f5Jer591fvSNrB/1n1mweJ1nDOBZ4FXF5Z1A/9CXFs4RWXRnrLo5KPyAFLhVXaApCbDZdcljvS5/V3cLf4Tfoq427qU+YPr8qhy/2wRSy1nFixsfx69s8CdD/wXTYmT3pOM4Y4PpbLo9HeqbMMVHyCpyXDZdYmj8Jk5vbOKSaPUmfu21f2z+PdIP2s7s2BTvBcT17QadykvY4gDTqos6vfo/AZrcICkJsNl1yWOFnENtro/Is6ORsr+2SKm2tRw+olxt8Lvbyea5Bpn1+cRY2hNGO6+orKo9tHZjdXoAElNhsuuSxwt4sqt7u9M9PgY8c1SNds/a1HD6Se+ycCp6fepxH0PpxRe/zvgIWBOej5FZTH8sqj60dFuXO7+lJl9EPh7M9sE/CfxT3i+mY0DvmpmnybmOv4rd3+q8N5n2xzLF8zsaWJMov8AxlqMffR1Ynjh7YC/cPdvl3l/Q13iaHy2mc0mksCviaapdxM9UtzM7k7rFHtn3Q5c4CX3zuqEOuyfZjbe3Z9M5XsUkZw2A79L2/mVmV1NDHK4ycz+ulD2E4k773/Qjlj6iXEUcaf/BamD0q3EndVHm9kz7n6ru19iMc7YFWa20N0H3YNOZVE/He/3W5cDZIqlFsNl1yGOlAhOJuYH+AHRJLXW3S82s3cTN+iNSklji8VNSJ8jhmVeU1ZcnVbl/mlmOwCrzexj7v4J4H+A3xA3Cn7czE5w918R/7cz0vp/SO8dlQ5EpR+MUnJcZTEU93JixNVLiZrY/JRcHyZGAbje3Z8c7DZUFjVVVdWGmPzmJ8SOsJzo238zcGgFsdRiuOwq4qDm1f0K/xaV7J/UtImyEF/jovICYviTO4muoYuAsamsbkplN6wYVRb1e1S78ZocqFMsLyeaIKZQYXt8p+Kghhd36/aoav+kpjMLFuKbTHQRPZi4Q3kpsBo4rrGvANNVFu0tizo8qg+gJgfqFEtdhssuNQ5qdHG37o+q9k9qVANvEdsU4BuF57sRszt+HzhdZVFeWVT9qHzsEo824+96TL5TdSyVxwDlx+E1uLg7UlS1f7r7bWZ2DjGvwwPufnUnt98fd99gZo+Z2dXuvtzdf2Nm9xLDXawvYXsqi5qozWi10nmp58ZzF3eJav7jxHWLnwN3eAc6H0jfzOzlxEXUE4FHveLeaOmC8rNmNoO4x2AKcD3RdfRMd19b4rZVFhVTwtjGpR5Ajd5ZF9PbO+syT72zpFpmNqnTNRwz252Yz+NH/awzjrjw/BSwzt1v6UBcKosKKWEIacTMDwBvd/evVh2PVCuN/trv3B/9vI+tqTaqsvhjShgC1K+6L9WyjMm70nrPTVi0tVJZ9KrVfBhSHXf/AnCMu29QshDPmPujcMf/zma22MqfvKsSKoteShjynLr0EpNqNA6CVtPJuzpJZdHaVpkFRWTw3DU8TIPKojXVMES2cZamMzWzMcR87W9197OJg+Ih6R6I9xM9gH6bDpDjiZvn3uXu36ko9LZTWfRPNQyRbdRIGA22U1QWeVTDENkGFUaDPTMtaowG+11iNNg90/LiaLCe3jsqdY7YKg6QKot8qmGIbIM0PEwvlUU+JQyRbZTXaG6aqqks8ihhiGzDvAaTd9WFymJgutNbRDQ8TIHKom9KGCICaHiYIpVFa0oYIvKcKkaDrSuVxfMpYYiISBbdhyEiIlmUMEREJIsShoiIZFHCEBGRLEoYIhnM7Doz+7WZ/bjqWESqooQhkufjwIKqgxCpkhKGSAZ3/xYxiqnINksJQ0REsihhiIhIFiUMERHJooQhIiJZlDBEMqQZ174H7GdmPWb2xqpjEuk0DT4oIiJZVMMQEZEsShgiIpJFCUNERLIoYYiISBYlDBERyaKEISIiWZQwREQkixKGiIhk+V/A0djTY9cgeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Can be visualized in bar graph for analysis reason (feature weight)\n",
    "pd.DataFrame(sorted_features).plot.bar(x=1,y=0, rot=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.617776082395575\n",
      "Testing Data Score: 0.5909610983981693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model6 = LogisticRegression()\n",
    "model6.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {model6.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model6.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'min_samples_split': [1, 2, 3],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "grid = GridSearchCV(model5, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.905, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.907, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.886, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.889, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.883, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.904, total=   2.5s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.906, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.884, total=   2.4s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.880, total=   2.2s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.879, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.905, total=   3.7s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.902, total=   3.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.885, total=   3.4s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.880, total=   3.2s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.885, total=   3.3s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.903, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.902, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.883, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.875, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.885, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.900, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.906, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.885, total=   2.4s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.882, total=   2.2s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.880, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.901, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.908, total=   3.3s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.884, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.882, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.880, total=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=200),\n",
       "             param_grid={'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.8937601423383958\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.896\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)\n",
    "print('Test Acc: %.3f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.75      0.78       411\n",
      "FALSE POSITIVE       0.83      0.85      0.84       484\n",
      "     CONFIRMED       0.96      1.00      0.98       853\n",
      "\n",
      "      accuracy                           0.90      1748\n",
      "     macro avg       0.87      0.86      0.87      1748\n",
      "  weighted avg       0.89      0.90      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CANDIDATE\",\"FALSE POSITIVE\",\"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.804\n",
      "k: 3, Train/Test Score: 0.910/0.831\n",
      "k: 5, Train/Test Score: 0.889/0.832\n",
      "k: 7, Train/Test Score: 0.880/0.830\n",
      "k: 9, Train/Test Score: 0.874/0.830\n",
      "k: 11, Train/Test Score: 0.869/0.831\n",
      "k: 13, Train/Test Score: 0.865/0.826\n",
      "k: 15, Train/Test Score: 0.861/0.824\n",
      "k: 17, Train/Test Score: 0.860/0.824\n",
      "k: 19, Train/Test Score: 0.856/0.830\n",
      "k: 21, Train/Test Score: 0.856/0.834\n",
      "k: 23, Train/Test Score: 0.854/0.831\n",
      "k: 25, Train/Test Score: 0.848/0.832\n",
      "k: 27, Train/Test Score: 0.844/0.832\n",
      "k: 29, Train/Test Score: 0.845/0.824\n"
     ]
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'SVM.sav'\n",
    "joblib.dump(your_model, 'SVM.sav')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
