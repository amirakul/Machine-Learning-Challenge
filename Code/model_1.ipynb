{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
    "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
    "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
    "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
    "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
    "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
    "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
    "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
    "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
    "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
    "       'koi_kepmag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new features based on sorted features\n",
    "X1 = df[['koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768901</td>\n",
       "      <td>7.380000e-05</td>\n",
       "      <td>-7.380000e-05</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>...</td>\n",
       "      <td>-171</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733726</td>\n",
       "      <td>6.060000e-06</td>\n",
       "      <td>-6.060000e-06</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>...</td>\n",
       "      <td>-175</td>\n",
       "      <td>4.578</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652707</td>\n",
       "      <td>6.540000e-05</td>\n",
       "      <td>-6.540000e-05</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>...</td>\n",
       "      <td>-189</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.953547</td>\n",
       "      <td>1.910000e-05</td>\n",
       "      <td>-1.910000e-05</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>4.536</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959319</td>\n",
       "      <td>5.150000e-07</td>\n",
       "      <td>-5.150000e-07</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>-77</td>\n",
       "      <td>4.359</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "6122              0              0              0              0    6.768901   \n",
       "6370              0              1              0              1    0.733726   \n",
       "2879              1              0              0              0    7.652707   \n",
       "107               0              0              0              0    7.953547   \n",
       "29                0              0              0              0    4.959319   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "6122     7.380000e-05    -7.380000e-05   133.077240          0.008440   \n",
       "6370     6.060000e-06    -6.060000e-06   132.020050          0.007950   \n",
       "2879     6.540000e-05    -6.540000e-05   134.460380          0.006190   \n",
       "107      1.910000e-05    -1.910000e-05   174.662240          0.001820   \n",
       "29       5.150000e-07    -5.150000e-07   172.258529          0.000083   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "6122         -0.008440  ...            -171      4.327           0.153   \n",
       "6370         -0.007950  ...            -175      4.578           0.033   \n",
       "2879         -0.006190  ...            -189      4.481           0.050   \n",
       "107          -0.001820  ...             -85      4.536           0.056   \n",
       "29           -0.000083  ...             -77      4.359           0.110   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "6122          -0.187     1.125          0.310         -0.207  294.40472   \n",
       "6370          -0.187     0.797          0.211         -0.056  284.50391   \n",
       "2879          -0.200     0.963          0.290         -0.097  295.50211   \n",
       "107           -0.016     0.779          0.023         -0.049  291.15878   \n",
       "29            -0.110     1.082          0.173         -0.130  292.16705   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "6122  39.351681      14.725  \n",
       "6370  42.463860      15.770  \n",
       "2879  38.983540      13.099  \n",
       "107   40.750271      15.660  \n",
       "29    48.727589      15.263  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 40)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model with SVC(different kernels)\n",
    "\n",
    "## 1. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8455082967766546\n",
      "Testing Data Score: 0.8415331807780321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model1 = SVC(kernel='linear')\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {model1.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model1.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.831012778943353\n",
      "Testing Data Score: 0.8255148741418764\n"
     ]
    }
   ],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "model2 = SVC(kernel='rbf')\n",
    "model2.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.846271218767881\n",
      "Testing Data Score: 0.8386727688787186\n"
     ]
    }
   ],
   "source": [
    "model3 = SVC(kernel='poly')\n",
    "model3.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model3.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model3.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501144164759725"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "model4 = clf.fit(X_train, y_train)\n",
    "model4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958810068649885"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "model5 = rf.fit(X_train, y_train)\n",
    "model5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.617776082395575\n",
      "Testing Data Score: 0.5909610983981693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model6 = LogisticRegression()\n",
    "model6.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {model6.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model6.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.804\n",
      "k: 3, Train/Test Score: 0.910/0.831\n",
      "k: 5, Train/Test Score: 0.889/0.832\n",
      "k: 7, Train/Test Score: 0.880/0.830\n",
      "k: 9, Train/Test Score: 0.874/0.830\n",
      "k: 11, Train/Test Score: 0.869/0.831\n",
      "k: 13, Train/Test Score: 0.865/0.826\n",
      "k: 15, Train/Test Score: 0.861/0.824\n",
      "k: 17, Train/Test Score: 0.860/0.824\n",
      "k: 19, Train/Test Score: 0.856/0.830\n",
      "k: 21, Train/Test Score: 0.856/0.834\n",
      "k: 23, Train/Test Score: 0.854/0.831\n",
      "k: 25, Train/Test Score: 0.848/0.832\n",
      "k: 27, Train/Test Score: 0.844/0.832\n",
      "k: 29, Train/Test Score: 0.845/0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXycZb3//9c7W5O2aZY2LU3TNimUlgK1hbaARUQ4yOLC8kMWRREX5HfEI0cPsuhx/Xrs1xU9elhEEAVBVEBEjhVBQRS6t7SllJamW7o3TdM9bfL5/nHdaafTSTJZJpNJPs/HYx5z7/d1ZzL3Z67lvi6ZGc4551x7ZaU7Ac455zKTBxDnnHMd4gHEOedch3gAcc451yEeQJxzznVITroT0B2GDBlilZWV6U6Gc85llHnz5m0zs7KW1veJAFJZWcncuXPTnQznnMsokta0tt6LsJxzznWIBxDnnHMd4gHEOedch3gAcc451yEeQJxzznVIygKIpAckbZG0pIX1kvQjSSslvSbptJh1F0laHq27PWZ5qaTnJK2I3ktSlf6nFtQwfcYLVN3+R6bPeIGnFtSk6lTOOZeRUpkD+TlwUSvrLwbGRq8bgbsBJGUDP4nWTwCulTQh2ud24HkzGws8H813uacW1HDHE4upqduHATV1+7jjicUeRJxzLkbKAoiZvQTUtrLJpcAvLHgVKJY0HJgGrDSzVWbWADwWbdu8z0PR9EPAZalI+3dmLmffwcajlu072Mh3Zi5Pxemccy4jpbMOZASwLmZ+fbSspeUAw8xsI0D0PrSlg0u6UdJcSXO3bt3aroRtqNvXruXOOdcXpTOAKMEya2V5u5jZfWY2xcymlJW1+CR+QuXFBe1a7pxzfVE6A8h6YGTMfAWwoZXlAJujYi6i9y2pSNitF46jIDf7qGUFudnceuG4VJzOOecyUjoDyNPAR6LWWGcCO6NiqTnAWElVkvKAa6Jtm/e5Ppq+Hvh9KhJ22eQRfOuKUxkR5Tj65WTxrStO5bLJI9rY0znn+o6UdaYo6VHgXGCIpPXAV4BcADO7B3gWuARYCewFbojWHZJ0MzATyAYeMLOl0WFnAI9L+jiwFvhAqtJ/2eQRXDZ5BF96ajFPLdjA+95WnqpTOedcRkpZADGza9tYb8CnW1j3LCHAxC/fDpzfJQlM0tTKUh5+dS3LNtZzyoii7jy1c871aP4kehumVZUCMLu6tRbJzjnX93gAacPwogJGlhZ4AHHOuTgeQJIwtbKUOatrCaVuzjnnwANIUqZVlrJ9TwOrtu1Jd1Kcc67H8ACShKlRPcgcL8ZyzrnDPIAkYcyQAQwZmOf1IM45F8MDSBIkMbWylNmrPYA451wzDyBJmlpZyvod+9i40ztUdM458ACSNH8exDnnjuYBJEknDR/EwH45HkCccy7iASRJ2Vni9NElzPF6EOecAzyAtMu0qlLe3LybHXsa0p0U55xLOw8g7TC1MtSDzF2zI80pcc659PMA0g4TK4rIy87yYiznnMMDSLvk52YzaWQxs7wi3TnnPIC019SqEpbW7GRvw6F0J8U559IqpQFE0kWSlktaKen2BOtLJD0p6TVJsyWdEi0fJ2lhzKte0i3Ruq9KqolZd0kqryHe1MpSDjUZC9bWdedpnXOux0lZAJGUDfwEuBiYAFwraULcZncCC81sIvAR4IcAZrbczCaZ2STgdMKQt0/G7PeD5vXR6IXd5vTRJWTJHyh0zrlU5kCmASvNbJWZNQCPAZfGbTMBeB7AzN4AKiUNi9vmfOAtM1uTwrQmrTA/lwnlgzyAOOf6vFQGkBHAupj59dGyWIuAKwAkTQNGAxVx21wDPBq37Oao2OsBSSWJTi7pRklzJc3dunVrR68hoamVpSxYt4OGQ01delznnMskqQwgSrAsfki/GUCJpIXAZ4AFwOHaaUl5wPuB38TsczdwPDAJ2Ah8L9HJzew+M5tiZlPKyso6fBGJTKssZf/BJpZs2Nmlx3XOuUySk8JjrwdGxsxXABtiNzCzeuAGAEkCqqNXs4uB+Wa2OWafw9OSfgo80+Upb8OUyiMDTJ02KmEGyDnner1U5kDmAGMlVUU5iWuAp2M3kFQcrQP4BPBSFFSaXUtc8ZWk4TGzlwNLujzlbSgr7MeYIQO8HsQ516elLAdiZock3QzMBLKBB8xsqaSbovX3ACcBv5DUCLwOfLx5f0n9gQuAT8Ud+tuSJhGKw1YnWN8tplWV8r9LNtHUZGRlJSqtc8653i2VRVhETWyfjVt2T8z0K8DYFvbdCwxOsPzDXZzMDplaWcpjc9bx5pZdjD9uULqT45xz3c6fRO+g5gGm5ngxlnOuj/IA0kEVJQUcNyjf+8VyzvVZHkA6SBLTqkqZs7oWs/jWyc451/t5AOmEqVWlbK4/wLrafelOinPOdTsPIJ0wLXoeZLaPD+Kc64M8gHTC2KEDKSrIZXb19nQnxTnnup0HkE7IyhJTK0uZs9qHuHXO9T0eQDppWlUJ1dv2sGXX/nQnxTnnupUHkE6aGtWDzPVciHOuj/EA0kmnjCiiIDfb+8VyzvU5HkA6KTc7i9NGF3sAcc71OR5AusDUylKWbaqnfv/BdCfFOee6TVIBRNJoSf8STRdIKkxtsjLLtMpSzGDeGq8Hcc71HW0GEEmfBH4L3BstqgCeSmWiMs3kUSXkZMk7VnTO9SnJ5EA+DUwH6gHMbAUwNJWJyjQFedmcMqLI60Gcc31KMgHkgJk1NM9IyuHYsc37vDOqSnlt/U72H2xMd1Kcc65bJBNAXpR0J1Ag6QLgN8Afkjm4pIskLZe0UtLtCdaXSHpS0muSZks6JWbdakmLJS2UNDdmeamk5yStiN57xKDkUytLaWhsYtG6unQnxTnnukUyAeQ2YCuwmDB87LPAl9raSVI28BPgYmACcK2kCXGb3QksNLOJwEeAH8atf5eZTTKzKTHLbgeeN7OxwPPRfNpNqQxxbI53rOic6yNaDSCSsoDFZvZTM/uAmV0ZTSdThDUNWGlmq6IisMeAS+O2mUAIApjZG0ClpGFtHPdS4KFo+iHgsiTSknLF/fMYN6zQB5hyzvUZrQYQM2sCFkka1YFjjwDWxcyvj5bFWgRcASBpGjCa0MoLQj3LnyXNk3RjzD7DzGxjlL6N9KAK/WlVpcxfs4NDjU3pTopzzqVcMkVYw4Glkp6X9HTzK4n9lGBZfM5lBlAiaSHwGWABcChaN93MTiMUgX1a0jlJnPPIyaUbJc2VNHfr1q3t2bXDplaVsqehkWUbd3XL+ZxzLp1yktjmax089npgZMx8BbAhdgMzqwduAJAkoDp6YWYbovctkp4kFIm9BGyWNNzMNkoaDmxJdHIzuw+4D2DKlCnd0mosdoCpUyuKuuOUzjmXNm3mQMzsReANoDB6LYuWtWUOMFZSlaQ84BrgqJyLpOJoHcAngJfMrF7SgOan3SUNAN4NLIm2exq4Ppq+Hvh9EmnpFscV5TOytMAHmHLO9QnJPIl+FTAb+ABwFTBL0pVt7Wdmh4CbgZnAMuBxM1sq6SZJN0WbnUQoHnuDUFT12Wj5MOBlSYuic//RzP4UrZsBXCBpBXBBNN9jTKsczNzVO0iunYFzzmWuZIqwvghMNbMtAJLKgL8QujdplZk9S2j2G7vsnpjpV4CxCfZbBbythWNuB85PIt1pMa2qhN/NX89bW/dwwtCB6U6Oc86lTDKV6FnNwSOyPcn9+qTmAab8eRDnXG+XTCD4k6SZkj4q6aPAH4H/TW2yMlfVkAEMGZjn/WI553q9NouwzOxWSVcAZxOa5t5nZk+mPGUZShLTqko9gDjner02A4ikKuBZM3simi+QVGlmq1OduEw1tbKUZxdvYkPdPsqLC9KdHOecS4lkirB+A8Q+Wt0YLXMt8HoQ51xfkEwAyYntzj2azmtl+z7vpOGDKOyX4/1iOed6tWQCyFZJ72+ekXQpsC11Scp82VnitNElPkKhc65XSyaA3ATcKWmtpHWE7t0/ldpkZb5pVaWs2LKbHXsa2t7YOecyUDKtsN4CzpQ0EJCZeU+BSZhWdaQe5N0nH5fm1DjnXNdrMQci6X2SRscs+hyhe5Gno5ZZrhUTK4rIy8ny5rzOuV6rtSKsbxJGIkTSe4HrgI8ROjO8p5X9HNAvJ5tJFcXeEss512u1FkDMzPZG01cAPzOzeWZ2P1CW+qRlvmlVpSzZUM+eA4fa3tg55zJMawFEkgZGw9qeTzT0bCQ/tcnqHaZWldLYZCxYW5fupDjnXJdrLYDcBSwE5hLGAJkLIGkysLEb0pbxThtVTJbCAFPOOdfbtNgKy8wekDSTMOb4ophVm4hGEXStK8zPZUL5IB9gyjnXK7X6HIiZ1ZjZAjNrilm20czWpj5pvcO0ysEsWFtHw6Gmtjd2zrkM4uN6pNi0qhIOHGpicc3OdCfFOee6VEoDiKSLJC2XtFLS7QnWl0h6UtJrkmZLOiVaPlLSXyUtk7RU0mdj9vmqpBpJC6PXJam8hs6a4h0rOud6qWTGRP+upJPbe2BJ2cBPCGOdTwCulTQhbrM7gYVmNhH4CPDDaPkh4PNmdhJwJvDpuH1/YGaTotez9GBDBvZjTNkAf6DQOdfrJJMDeQO4T9IsSTdJKkry2NOAlWa2KurB9zHg0rhtJhA1DzazN4BKScOiepb50fJdwDJgRJLn7XHOqCpl7upampos3Ulxzrku02YAMbP7zWw6IYdQCbwm6VeS3tXGriOAdTHz6zk2CCwiPKSIpGnAaKAidgNJlcBkYFbM4pujYq8HJJUkOrmkGyXNlTR369atbSQ1taZWllK//xDLN3s3Ys653iOpOpCoOGp89NpGuPF/TtJjre2WYFn8T/AZQImkhcBngAWE4qvm8w4EfgfcYmb10eK7geOBSYTnUb6X6ORmdp+ZTTGzKWVl6X1w3geYcs71RsnUgXwfWA5cAvyXmZ1uZv/XzN5HyBm0ZD0wMma+AtgQu4GZ1ZvZDWY2iZDDKQOqo/PmEoLHI83D6Ub7bDazxqhp8U8JRWU9WkVJAcOL8n2AKedcr5JMDmQJMNHMPmVms+PWtXbzngOMlVQlKQ+4htAR42GSiqN1AJ8AXjKzekkCfkZ4Av77cfsMj5m9PEpfjyaJqZWlzKmuxczrQZxzvUMyAWQHkNs8E930LwMwsxYfbjCzQ8DNwExCJfjjZrY0qoi/KdrsJGCppDcIrbWam+tOBz4MnJegue63JS2W9BrwLuDfk73YdJpWVcqWXQdYW7u37Y2dcy4DtDmgFPAVM3uyecbM6iR9BXiqrR2jJrbPxi27J2b6FWBsgv1eJnEdCmb24STS3OM0DzA1u7qW0YMHpDk1zjnXecnkQBJtk0zgcTFOKBtIcf9cfx7EOddrJBNA5kr6vqTjJY2R9ANgXqoT1ttkZYkpo0u9JZZzrtdIJoB8BmgAfg38BtgPfDqVieqtzqgqZfX2vWzZtT/dSXHOuU5rsyjKzPYAx/Rj5dpvalQPMqd6B++ZOLyNrZ1zrmdrM4BIKgO+AJxMzEiEZnZeCtPVK51cPoiC3GxmV2/3AOKcy3jJFGE9QugPqwr4GrCa8IyHa6fc7CxOG13M7NU70p0U55zrtGQCyGAz+xlw0MxeNLOPEXrIdR1Q2C+XZRvrqbr9j0yf8QJPLahJd5Kcc65DkmmOezB63yjpPYTuSCpa2d614KkFNbywfAsQOgWrqdvHHU8sBuCyyRnb2bBzro9KJgfyf6Iu3D8P/AdwPxny9HdP852Zy48Z2nbfwUa+M3N5mlLknHMd12oOJOqFd6yZPQPsJHQd4jpoQ92+di13zrmerNUciJk1Au/vprT0euXFBe1a7pxzPVkyRVj/lPRjSe+QdFrzK+Up64VuvXAcBbnZxyw/ubzQe+l1zmWcZCrR3x69fz1mmQH+HEg7NVeUf2fmcjbU7WN4cT6jSvrz59e38LU/vM6X3zuBrKyEfUg651yPk8yT6F7v0YUumzziqBZXZsY3nlnGA/+oZm/DIb51xUSyPYg45zJAMk+ifznRcjP7eqLlrn0k8Z/vPYnC/Bx++PwK9hxo5AdXTyIvJ6nRhp1zLm2SKcLaEzOdD7yXMECU6yKS+PcLTmRgvxy++ewy9jYc4u7rTic/QX2Jc871FG3+zDWz78W8vgmcCyT11JukiyQtl7RS0jEdMkoqkfSkpNckzZZ0Slv7SiqV9JykFdF7SVJXmgE+ec4Y/uvyU/nbm1u5/oHZ7D5wKN1Jcs65FnWknKQ/MKatjaJnSH5CGKp2AnCtpAlxm90JLDSzicBHgB8mse/twPNmNhZ4nl7WU/AHzxjFXVdPYu6aHXzo/lnU7W1Id5Kccy6hNgNI8/jj0WspsJzoRt+GacBKM1tlZg3AY8ClcdtMIAQBzOwNoFLSsDb2vRR4KJp+CLgsibRklEsnjeCe605n2cZ6rr73VR8/xDnXIyWTA3kv8L7o9W6g3Mx+nMR+I4B1MfPrObboaxFwBYCkacBoQj9bre07zMw2AkTvQxOdXNKNkuZKmrt169YkktuzXDBhGA9+dCpra/dy1T2vsH7H3nQnyTnnjpJMABkO1JrZGjOrAfIlnZHEfonaosY/LTcDKJG0kDDy4QLgUJL7tsrM7jOzKWY2paysrD279hjTTxjCw5+YxvY9DVx1zyus2ro73UlyzrnDkgkgdwOxd6690bK2rAdGxsxXEHryPczM6s3sBjObRKgDKQOq29h3s6ThANH7liTSkrFOH13KYzeeyYFDTVx17yss21if7iQ55xyQXACRxfSzYWZNJNf8dw4wVlKVpDzgGuDpow4sFUfrAD4BvGRm9W3s+zRwfTR9PfD7JNKS0U4uL+LXnzqLnKwsrr73FRas9QGpnHPpl0wAWSXp3yTlRq/PAqva2snMDgE3AzMJz408bmZLJd0k6aZos5OApZLeILS4+mxr+0b7zAAukLQCuCCa7/VOGDqQ39x0FsX987ju/lm88tb2dCfJOdfHqa1O/CQNBX5E6PvKCK2mbjGzjCk6mjJlis2dOzfdyegSm+v3c939s1hbu5e7rzuN88YPS3eSnHO9lKR5ZjalpfXJPEi4xcyuMbOhZjbMzD6YScGjtxk2KJ9ff+osThxWyI2/mMcfFm1oeyfnnEuBZJ4DeUhSccx8iaQHUpss15rSAXk88skzmDyqmH97bAG/nrM23UlyzvVByVSGTzSzuuYZM9shaXIK0+SSMCg/l1987Aw+9fA8bvvdYl55aztzVu9gQ90+yosLuPXCcT7OunMupZKpRM+K7W9KUinJBR6XYgV52fz0I6czccQgnlq4gZq6fRhQU7ePO55YzFMLatKdROdcL5ZMAPkeYVTCb0j6BvBP4DupTZZLVr+cbLbtOba/rH0HG/nOzOVpSJFzrq9IZkCpX0iaS2iFJeAKM3s95SlzSdtYl7ivrJq6fexraKQgz7uFd851vaR64zWz16P+r54FrpC0JLXJcu1RXlzQ4rq3z3ie7z/3Jtt2H+jGFDnn+oJkWmENl3SLpNnAUiAbuDblKXNJu/XCcRTEDT5VkJvFze86ntNHl/Kj51fw9hkvcMcTr7Fyi/en5ZzrGi0WYUn6JCFQVACPE7oa+b2Zfa2b0uaS1Nza6jszlydshfXW1t387OVqfjdvPY/OXsf544fyiXeM4cwxpUg+/rpzrmNafBJdUgPwCvB5M5sbLVtlZm0OJtXT9KYn0Ttj++4D/PLVNfzylTVs39PAKSMG8cl3jOGSU4eTm+1jsDvnjtbWk+itBZAhwAcIuZBhhFzIR81sZMIdejAPIEfbf7CRJ+bXcP/Lq1i1dQ/lRfl87Owqrp46ksL83HQnzznXQ3Q4gMQdpILQI+61hCFtnzSzO7sslSnmASSxpibjhTe28NO/r2JWdS2F/XK4ZtpIbpheRXlxAU8tqGmxWMw51/t1SQCJO+A44JpMqgvxANK219bX8dO/V/Ps4o0ImFhRxNIN9Rw41HR4m4LcbL51xakeRJzrI7o8gGQiDyDJW79jLw/+YzUPvFydcAjIEcUF/OP287o9Xc657tfp3nhd31JR0p//fO+EFtfX1O1j0bo6Gpt6/w8P51zrvE8rl1B5cQE1dfsSrrv0J/9gUH4Obz9+CNPHDuHsE4ZQObi/Nwl2ro9pM4BIOi3B4p3AmmjkwNb2vQj4IeHhw/vNbEbc+iLgYWBUlJbvmtmDUT3Lr2M2HQN82czukvRV4JPA1mjdnWb2bFvX4drn1gvHcccTi9l3sPHwsoLcbO64ZDxFBbn8Y+U2/rFyO39augkIRVvTTxjM9BOG8Pbjh1BW2C9dSXfOdZNkRiR8FTgNeI3QF9Yp0fRg4CYz+3ML+2UDbxKGnV1PGOf82th+tCTdCRSZ2W2SyoDlwHFm1hB3nBrgDDNbEwWQ3Wb23WQv0utAOqatVlhmxprte3l55Tb+sXIb/3xrOzv3HQRg/HGFTD8h5E6mVZUyoF9O0sd1zvUMbdWBJFOEtRr4ePOY5JImALcC3wCeABIGEGAasNLMVkX7PQZcCsR2xGhAoULZx0CgFojP1ZwPvGVma5JIq+tCl00e0eqNXRKVQwZQOWQA1505msYmY+mGnYcDyi9fXcPPXq4mJ0ucNqqE6ScMocmauPelVew/GFp3NXc933w+51zmSCaAjG8OHhA6VpQ02cxWtVHmPQJYFzO/HjgjbpsfA08DG4BC4Goza4rb5hrg0bhlN0v6CDCX8KT8jviTS7oRuBFg1KhRraXTdZHsLDGxopiJFcX867knsP9gI/PW7DgcUO56/k0SZXibu573AOJcZkmmFdZySXdLemf0+h/gTUn9gIOt7JcousTfPi4EFgLlwCTgx5IGHT6AlAe8H/hNzD53A8dH228kjFdy7InM7jOzKWY2paysrPUrdCmRn5vN9BOGcNtF43n65rNZ8J8XtLhtTd0+/vv5Fby6ajv7Y+pdnHM9VzI5kI8C/wrcQggKLwP/QQge72plv/VAbLcnFYScRqwbgBkWKmJWSqoGxgOzo/UXA/PNbHPzDrHTkn4KPJPENbgeoLh/HiNaaN2VkyW+/5eQQ8nLzuLUiiKmVpYyraqE00eXUlTgXaw419MkM6DUPsKv/ES/9FvrG3wOMFZSFaES/Brgg3HbrCXUcfxd0jBgHLAqZv21xBVfSRpuZhuj2csBH5skg7TUuutbV5zKu8YNZe6aWmavrmVOdS33/30V97xoSDBuWCFnVJUytaqUaZWlDB2Uf8yxvXLeue6VTCus6cBXgdHEBJxkeuWVdAlwF6EZ7wNm9k1JN0X73yOpHPg5MJyQu5lhZg9H+/Yn1KGMMbOdMcf8JaH4yggV/J+KCSgJeSusniXZG/2+hkYWrNvBnOodzFldy/y1O9jbEALP6MH9Qw6lMgSVhWt3cOeTSxIGJg8iznVMp7sykfQG8O/APODwt9PMtndVIlPNA0jvcLCxidc31DNndS2zq2uZs7qWHXtDNVyWINHD8d71inMd1xUBZJaZxbeeyigeQHonM+OtrbuZVV3LF59suSTzM+edwLjjChl/XCGVgweQ42OfOJeUrngO5K+SvkN45uPwwNpmNr8L0udch0nihKGFnDC0kP/561stVs7/z9/eOtx3V15OFmOHDmTccYWcdNygw4GlrLBfi12xeN2Kc4klE0Cacx+xUcgALxdwPUZrlfMXnXIcK7fsZvmmXSzfvIs3Nu3i5RXbeGJ+zeFtS/rnMj4moIyLXn9euvmo4/qDj84d4d25u16jvTmFHXsaeGPTLpZvqueNTSGwvLl51+GKegmypIQ9D3vdiusLOjOk7XVm9rCkzyVab2bf76I0ppwHEJespiZj3Y69UWDZxfefe7PFbd9z6nDGDhvIicMKOXHYQEYPHuBjy7tepTN1IAOi98IE63p/tsX1SVlZYvTgAYwePIALTz6OX89Zl7BuJT8niyUbdvLsko2Hu2fJzRZjhgw8KqiMHVbI6NL+x1Tce72K6w1aDCBmdm80+Rcz+0fsuujZEOd6vdbqVi6bPIJ9DY28tXU3b27exZubd7Ni8y4Wra/jmdeOPJqUl53FmLIBh4NK7Z4GHpm19vBwwV6v4jJVMs1455vZaW0t68m8CMt1RkdyC3sbDrFyy+7DQaU5wLQ0SBfAgLxsPnnOGEoH5IVX/zxKB4b34v555OW0XTzmORvXlTpTB3IW8HZCH1g/iFk1CLjczN7WlQlNJQ8grqfYc+AQp3xlZofKgAvzcygdkEdJ/zwGD8ijZMCR99L+eby5eRe/fHXN4ZwN+NP4rnM6UweSRxijI4ej60HqgSu7JnnO9S0D+uW0OFzwiOICXrz1XHbsPciOvQ3U7jny2rGnge17Gg4v31S/n2Ub69m+p+GogBFv38FGvvTUEprMGDu0kBOGDqQgLzuVl+j6kGSKsEY3D+YkKQsYaGb13ZG4ruI5ENeTPLWgptV6lfYwM/YdbKR2TwPv+L9/bTNnI8HIkv6HK/hPHDbwcGDJz205sKSqaMyL3Hq2rngS/VtRB4iNhP6wiiR938y+01WJdK4vab5BdsWNUxL983Lon9dyzqa8OJ9ffOyMqC5mN29u2cWKzbv42/KtHIqecckSjCrtfzionDiskLFDCxlTNoA/LdmUkocp4wOpNybIPMnkQBaa2SRJHwJOB24D5pnZxO5IYFfwHIjrC9qbsznY2MTqbXtCUNm8ixVbQoCp3rbn8MOTWdHDlIcSPExZVJDDZ84b2+H0/vcLK9i5L34E6xDw/nn7+R0+rus6XdGZ4lJC9+m/An5sZi9KWuSV6M71PF1RJNRwqInqbXtCUNm8ix+9sDJFqW1ZeVE+w4sLKC8uoLwon/LiAoZH7+XFBZT0z/W+y7pBVxRh3UsYd2MR8JKk0YSKdOdcD3PZ5BGdvlnm5WQd7gsM4HfzaxIWjQ0vymfmv5/T4fNc+IOX2Lhz/zHLC/vlcObxg9lQt4/X1tcxc8l+GhqPbiiQn5tFeVEBw4vzo/cCRhTnU71tDw/+Y7U/Y9NNOtQXlqQcMzs279lDeQ7EuY7rykr/jhy3qcnYvqeBjTv3saFuHxvq9rOhbh8bd+5nQ7Rsy64DtHYrG1rYj+p6Re4AABd2SURBVFfvOJ+srMS5FpdYVxRhDQP+Cyg3s4slTQDOMrOfJXHyi4AfEkYkvN/MZsStLwIeBkYRckPfNbMHo3WrgV2EyvtDzRchqRT4NVBJyBldZWY7WkuHBxDnOqent8I62NjEpp37OefbLbdEK+6fy7TKUs4YM5gzqko5afggsj2gtKorAsj/Ag8CXzSzt0nKARaY2alt7JcNvAlcAKwnjJF+rZm9HrPNnUCRmd0mqQxYDhxnZg1RAJliZtvijvttoNbMZki6HSgxs9taS4sHEOf6hukzXkhY3FbcP5cLThrGrOpa1tbuBWBQfg7Tqko5o2owZ44ZzIRyDyjxOlwHElNMNcTMHpd0B4CZHZLU2NJ+MaYBK81sVXS8x4BLgddjtjGgUKE2bCBQC7RVNHYpcG40/RDwN0LLMOdcH9dS32Vffd/Jh3M2G+r2Mat6O7NW1TKrupa/LNsChLqXKZUlnDlmMGeMGcwp5YOO6gTTK+eP1Vol+mzgNGCPpMFEPfBKOhPYmcSxRwDrYubXc2RwqmY/Bp4GNhCedr/azJprywz4syQD7jWz+6Llw8xsI4CZbZQ0NNHJJd0I3AgwatSoJJLrnMt0yTxjU15cwOWTK7h8cgUAm+v38+qq7cyqruXVVdv56/KtQOibbEplKWeMKeXAwSbufekt9h/0yvlYrfWFtcDMJks6Dfhv4BRgCVAGXGlmr7V6YOkDwIVm9olo/sPANDP7TMw2VwLTgc8BxwPPAW8zs3pJ5Wa2IQoQzwGfMbOXJNWZWXHMMXaYWUlrafEiLOdcsrbs2s/sKJjMWlXLii27W9y2tw8s1plmvGUxg0k9CTwLiDAu+r8ArQYQQo5jZMx8BSGnEesGYIaFKLZSUjUwHphtZhsAzGyLpCcJRWIvAZslDY9yH8OBLW2kwznnkja0MJ/3TiznvRPLAdi2+wBT/s9fEm5bU7ePm345j1MriphYUcSpI4oo7p/XnclNq9YCSDahXiK+Vql/kseeA4yVVAXUANcAH4zbZi1wPvD3qLXXOGCVpAFAlpntiqbfDXw92udp4HpgRvT++yTT45xz7TZkYD9GtNBNTEFuNm9squdPSzcdXjaqtH8IKCOKOLWiiFNGFDEoP7c7kwx0T51NawFko5l9vZX1rYoq228GZhKC0QNmtjTqVwszuwf4BvBzSYsJgeo2M9smaQzwZPSkaQ7wKzP7U3ToGcDjkj5OCEAf6GganXMuGW0NLLZz70GWbNjJa+t3srimjkXr6vhjzKBiY4YM4NQohzKxopiTywcxoF+4/abiRv+7eev44lNLUl5n02YdSJedKY28DsQ511ntvdHX7mlgcc1OFq+viwLLzsNP3ktwQtlAigpyWLR+Jwcbj9yH87KzuO7MUUysKGZPwyH2NTSyt6HxqOl90XzsdPO6vQ2HjjperPbW2XRmQKlSM6tN+kw9mAcQ51xPsGXXfpbURDmV9Tv56/ItJOinMqG8nCz652XTPzeb/v1y6J+XTUFuNgP65VAQLW+evvtvbyU8hoDqGe9JOr0drkTvLcHDOed6iqGF+Zw3Pp/zxg8DoOr2PybcTsDzn3/nUcEh9pmUtjy9cEMLXfsXdCjdLUk+Rc4557pUSzf08uICxpQNZNigfAbl57YreECosymIGyCsIDebWy8c1+G0JuIBxDnn0iRVN/rLJo/gW1ecyojiAkSo++hs55eJJNOdu3POuRToytEpEx071U/JewBxzrk06o4bfap4EZZzzrkO8QDinHOuQzyAOOfS4+W7oPqlo5dVvxSWu4zgAaQ38C+iy0QjToPffPTI/271S2F+xGnpTFX3yvDvrgeQ3sC/iC5THGqALctg6VOwdhYMOwV+eTn8cBI8ciWMvRBqq2HFc7BpCeytpdXBzuOl6oacquNm+HfXW2F1p5fvCv8YVeccWVb9EtTMh7NvaXv/xkOwbwfs3QZ7t4fXnm3hSzZqOjx8JQyfCFteh3NuhUEjwhc2pw90L93Zv61rWUf+tvt3wrYVsO1N2Lr8yPuO1WAxA5oWjYLC4bCjGnL7w6JHYdGvjj5WTj4UHhf+nwuHw6DhUFge814e1mfnHrkhf+DnIb3NN+QP/Lxzf4Phk+E318P7fwIVU2D13+GZz8GF34QNC6GxIbwOHYh5PwiNB1pf1tgQjv3wlTB6OmxcAFf94ui/dQ/W5pjovUGP6Qsr9p+58h2wYiY8cROc9yUoHhkXFLaHwNAcLPZsg/11LR87rzD00HagPm6FoKgCSiqhZHT0XgXF0fSAIWG/eKm6IafquLF/2/gbR4Z8GXuslv62Vz4IQ06EbctDsNi6/Mj0riM90ZKVC4OPD9uWjYMh42DI2PCqmReONeXjMPdn8P/dD4PHhv3ra6B+I+zaEL1vhPoN4dV4IC6RggFlIahk94NNr0H55HBzH/tuGFgWdyNPdMNvXtZw7E2+qa2RtttDkNMvpDM7N0zvr4eGXWHdiRfBpGvDe06/LjxvB1La0c4Ue5MeE0AAVr4Aj14FTY1wePTeOFm50H9wuLn3Lw3T/YdE74NhwOAj0/2jbdbNCl/E0z8Gc++Hd94O+UXhF1/sa/emo8+VOyAKKnGvPdvguS91/Q25tRv96LOhYTcc2HXkvfl1eL4eDrSwze4t4SYzcFgItmd/DqZ+PPwdXee8ORN+9wkonxSKnkpGw65NR/9gySuEshOPBIjmYFFSCdkJCjs6GvTNQk68fsORoHJUwNkI21fCof2grPA/npMH2dGr+eZ9zLK46UTLql+CVX8NRW2nXNG+fZuns3KO/tHWfN0TLoWFj0JuAeyrhfxiOPVKeNsHw4+uRD/0UswDCD0sgPzhFpj3YJiuOhcmXhUFisFRsBgC/Qrb98/Sni9iw16oWwt1a44NLjtWw8G9R2+vrHBD3rM1/DLML+rIVR9t/07YviJc656t4ZiNDSEgJCM7L/yN8gZCv0HQb2CY71cYiko2LQZlHykqGXIijDoLRr89vBePSsuXMaM0Hgy5wlV/C6/1s4/8Cs8dABWnh7/rkHFHgkbhce37u6Y6NzrlYzD3ga7LhR4+bpRb6orjtvTdfftnQh3QG8+EQDjkRHjbtTDxaijqvocOPYDQgwLI3AfhmVsgpyD8g3TVP2FXfRHNwg09NqC8/nvYvCTcdEuqOpfOWDuqQyArGwcV044NBPHBIXa+pWx9/Bf8nV8IAXPtK+FX84GdYbtBI6KAchaMejuUjYesPt6exCwUQTUHjNUvHylSGf42KD0eVj4Hp38UFj7Sc4sGU1WUmarjtvXd3b8zNDhY9Gj4P0Yw5lyY9EEY/17IS3aA2I5JawCRdBHwQ8KIhPeb2Yy49UXAw8AoQoX+d83sQUkjgV8AxwFNwH1m9sNon68CnwS2Roe508yebS0dPSKArJ0FD14cftF/6Ldw/Lk9v5w+Fb+4UnXctr7gTY2hccGaV2DtP8N7c3FeQQmMPDPkUEa/Pdwws6MhSHtz5fzOGqh+MQoaLx75e5RUhZvUmHPDdW9ekjn1S5lWd9cetatg0WMhmNStDUWGJ18airhGnZWSH0FpCyCSsoE3gQuA9YQx0q81s9djtrkTKDKz2ySVAcsJQWMwMNzM5ksqBOYBl5nZ61EA2W1m3002LWkPIPUb4b53hmKaS38C42MGdOmpN6Pe9ksunlnIBR0OKP8MX1AIrYEqpoTcSb8B8PcfwFUPdV1603WT278z5Cyacxnb3gzb9B8CY94ZBYx3hvqN7kiv65impvA/u/BReP2pUPRbPDoUcb3tGiit6rLPLJ0B5Czgq2Z2YTR/B4CZfStmmzuAkcCngUrgOeBEs6NrlyX9HvixmT2XcQHk0AF48JLQ9v0Tf4FhE9KTjvbqzb/kWrJr85Hcydp/hjJoLOQalRUqg+vWwfHnhaK3flGxWl5M0dtRRXDRe/wvw+4KziufD/MnXhSC44b5oeFGbv+Q0xpzbngNPdmL8DJVwx5Y9kxo+rzqRcDCD5+K02HBI53+4ZPOAHIlcJGZfSKa/zBwhpndHLNNIfA0MB4oBK42sz/GHacSeAk4xczqowDyUaAemAt83sx2tJaWtAUQM3j6M7Dgl3DVL2HC+7s/Da7j9u+EdbND7mTJb0OxQb+i0KJofz00HUzuOLHBpF9hCDyHGmDDAhh6Emx9IwSlQeWdT3P9BnjrhVChvWN1WKZsGHH6kYBRMbVvPBvU1+xcD6/9OuRMtq+ArLwwtOHk60JdZgd+oHR4SNsukKg5Rny0uhBYCJwHHA88J+nvZlYPIGkg8DvgluZlwN3AN6JjfQP4HvCxY04u3QjcCDBq1KhOX0yHzP1ZCB7v+A8PHpkovwjGXhAq7ec/BOd84eg6m0MHoibF9TFNiuPnEy2L3nP6wcaFoVHFulldmHCF4FF+WnigtHJ617Secz1bUQW84/Oh+XrNPFj4K1jwcGiJds4XUlJflcoAsp5QPNWsAtgQt80NwAwL2aCVkqoJuZHZknIJweMRM3uieQcz29w8LemnwDOJTm5m9wH3QciBdP5y2mnNP+F/bwvtxd91Z7ef3nWR+Kx/1TuOns/pF57L6ehx44NSV6W3uZVfv4EePPoaKdThHdwb6kim/Fv4X6h6R5cHkVQWfM4BxkqqkpQHXEMoroq1FjgfQNIwYBywSpKAnwHLzOz7sTtIGh4zezmwJEXp77idNfD4R0LF1hX3QVZ22/u4nqlm/tE396pzwnzN/I4fMzYonffF8B7bH1JPO67LPEf9L3wpZf8LqW7GewlwF6EZ7wNm9k1JNwGY2T2SyoGfA8MJRV4zzOxhSWcDfwcWE5rxQtRcV9IvgUmEIqzVwKfMLKbfhGN1ax3Iwf2hue62FfDJ50Nlq3Ox+mIDBde9Mr0VVk/SbQHEDH7/6fCg1TW/Orq5rnPOZZi2Aoi33etKs38agsc7b/Pg4Zzr9TyAdJXVL8OfbocTLw4dGTrnXC/nAaQr1K2Dx6+H0jFRpbn/WZ1zvZ/f6Trr4D749YdCNyXXPgr5g9KdIuec6xY+ImFnmMEfPgsbF8G1j4UxEJxzro/wHEhnvHp36Drg3Dth3MXpTo1zznUrDyAdtepF+POXQp/859ya7tQ451y38wDSETvWhKc6B58Al9/jlebOuT7J73zt1bA3VJo3NYaHBfsVpjtFzjmXFl6J3h7N3bNvWgIffByGnJDuFDnnXNp4DqQ9XvlxGBfivC/Bie9Od2qccy6tPIAk660X4Lkvw0nvD33uO+dcH+cBJBm11fDbj8GQcXDZ3aG/feec6+M8gCTy8l1H+s1v2AOPfSgMQTr2gjBAj3POOQ8gCY04LTTTXfVi6J59y9IwKNTYC9KdMuec6zG8FVYizaPO/erqMCxkbn+45pGUjCnsnHOZynMgLak6B44/P0yf9WkPHs45FyelAUTSRZKWS1op6ZhBMiQVSfqDpEWSlkq6oa19JZVKek7Siui9JCWJr34J1v4TzvkCzH3Ax5V2zrk4KQsgkrKBnwAXAxOAayVNiNvs08DrZvY24Fzge5Ly2tj3duB5MxsLPB/Nd62jBqT/YsoGpHfOuUyWyhzINGClma0yswbgMeDSuG0MKJQkYCBQCxxqY99LgYei6YeAy7o85TXzQ9BoLrZqrhOpmd/lp3LOuUyVykr0EcC6mPn1wBlx2/wYeBrYABQCV5tZk6TW9h1mZhsBzGyjpKGJTi7pRuBGgFGjRrUv5WffcuyyqnO8HsQ552KkMgeS6Gk7i5u/EFgIlAOTgB9LGpTkvq0ys/vMbIqZTSkrK2vPrs4555KQygCyHhgZM19ByGnEugF4woKVQDUwvo19N0saDhC9b0lB2p1zzrUhlQFkDjBWUpWkPOAaQnFVrLXA+QCShgHjgFVt7Ps0cH00fT3w+xReg3POuRakrA7EzA5JuhmYCWQDD5jZUkk3RevvAb4B/FzSYkKx1W1mtg0g0b7RoWcAj0v6OCEAfSBV1+Ccc65lMmtX1UJGmjJlis2dOzfdyXDOuYwiaZ6ZTWlxfV8IIJK2AmtiFg0BtqUpOanWW6/Nryvz9NZr60vXNdrMWmyF1CcCSDxJc1uLqpmst16bX1fm6a3X5td1hPeF5ZxzrkM8gDjnnOuQvhpA7kt3AlKot16bX1fm6a3X5tcV6ZN1IM455zqvr+ZAnHPOdZIHEOeccx3S5wJIW4NcZSpJqyUtlrRQUkY/NSnpAUlbJC2JWdY9A4mlUAvX9VVJNdHntlDSJelMY0dIGinpr5KWRQPDfTZantGfWSvX1Rs+s3xJs2MG8/tatLxdn1mfqgOJBqp6E7iA0GHjHOBaM3s9rQnrApJWA1Oau4LJZJLOAXYDvzCzU6Jl3wZqzWxGFPhLzOy2dKazvVq4rq8Cu83su+lMW2dEnZoON7P5kgqBeYRxej5KBn9mrVzXVWT+ZyZggJntlpQLvAx8FriCdnxmfS0HkswgVy7NzOwlwuBisVI/kFiKtXBdGc/MNprZ/Gh6F7CMMB5QRn9mrVxXxot6QN8dzeZGL6Odn1lfCyCJBqrqFf8QhA//z5LmRYNp9TZHDSQGJBxILEPdLOm1qIgro4p54kmqBCYDs+hFn1ncdUEv+MwkZUtaSBgS4zkza/dn1tcCSKcHqurBppvZaYRx5D8dFZe4nu9u4HjCgGobge+lNzkdJ2kg8DvgFjOrT3d6ukqC6+oVn5mZNZrZJMJ4S9MkndLeY/S1AJLMIFcZycw2RO9bgCcJxXW9Sa8cSMzMNkdf5Cbgp2To5xaVo/8OeMTMnogWZ/xnlui6estn1szM6oC/ARfRzs+srwWQZAa5yjiSBkSVfEgaALwbWNL6XhmnVw4k1vxljVxOBn5uUYXsz4BlZvb9mFUZ/Zm1dF295DMrk1QcTRcA/wK8QTs/sz7VCgsganJ3F0cGqvpmmpPUaZLGEHIdEAYJ+1UmX5ekR4FzCd1Lbwa+AjwFPA6MIhpIzMwyqkK6hes6l1AUYsBq4FPNZdCZQtLZwN+BxUBTtPhOQn1Bxn5mrVzXtWT+ZzaRUEmeTchIPG5mX5c0mHZ8Zn0ugDjnnOsafa0IyznnXBfxAOKcc65DPIA455zrEA8gzjnnOsQDiHPOuQ7xAOJcRFJlbE+5XXjcr0v6lza2+aqk/+iuNDnXFXLSnQDnejsz+3K6zi0p28wa03V+17t5DsS5BCSNkbRA0tS45edK+puk30p6Q9Ij0RPLSDpd0otRh5YzY7qE+LmkK6PpS6L9Xpb0I0nPxBx+QnTsVZL+LWZ5jqSHos77fiupf3Ss86M0Lo469esXLV8t6cuSXgY+IOnfJL0e7f9YCv9sro/xAOJcHEnjCP0f3WBmcxJsMhm4BZgAjAGmR30m/TdwpZmdDjwAHNUbgKR84F7gYjM7GyiLO+544EJC30pfiY4JMA64z8wmAvXAv0bH+jlwtZmdSihN+P9jjrXfzM42s8eA24HJ0f43tfsP4lwLPIA4d7QyQv8/15nZwha2mW1m66PO9BYClYSb/CnAc1EX2V8idNYZazywysyqo/lH49b/0cwORIOCbQGGRcvXmdk/oumHgbOj81Wb2ZvR8oeA2B6Yfx0z/RrwiKTrgEMtX7pz7eN1IM4dbSdhzJjpwNIWtjkQM91I+B4JWGpmZ7Vy7ETDCbR1XDh2yAFL4lh7YqbfQwgu7wf+U9LJZuaBxHWa50CcO1oDYRS2j0j6YDv2Ww6USToLQjfgkk6O2+YNYEw0OBHA1Ukee1TzcQkd+b0cHatS0gnR8g8DL8bvKCkLGGlmfwW+ABQDA5M8r3Ot8hyIc3HMbI+k9xKKo/aYWZvdkJtZQ1RR/iNJRYTv1l3E5GLMbJ+kfwX+JGkbMDvJJC0Drpd0L7ACuNvM9ku6AfiNpBzCUAX3JNg3G3g4SpOAH0TjPzjXad4br3PdSNJAM9sdtdz6CbDCzH6Q7nQ51xFehOVc9/pkVMm+FCgitMpyLiN5DsQ551yHeA7EOedch3gAcc451yEeQJxzznWIBxDnnHMd4gHEOedch/w/45q2iHfoR/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize\n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'min_samples_split': [1, 2, 3],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "grid = GridSearchCV(model5, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.905, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.907, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.886, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.889, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.883, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.904, total=   2.5s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.906, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.884, total=   2.4s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.880, total=   2.2s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.879, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.905, total=   3.7s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.902, total=   3.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.885, total=   3.4s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.880, total=   3.2s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.885, total=   3.3s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.903, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.902, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.883, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.875, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.885, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.900, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.906, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.885, total=   2.4s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.882, total=   2.2s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.880, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.901, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.908, total=   3.3s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.884, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.882, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.880, total=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=200),\n",
       "             param_grid={'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.8937601423383958\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.896\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)\n",
    "print('Test Acc: %.3f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.75      0.78       411\n",
      "FALSE POSITIVE       0.83      0.85      0.84       484\n",
      "     CONFIRMED       0.96      1.00      0.98       853\n",
      "\n",
      "      accuracy                           0.90      1748\n",
      "     macro avg       0.87      0.86      0.87      1748\n",
      "  weighted avg       0.89      0.90      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CANDIDATE\",\"FALSE POSITIVE\",\"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1042627841623718, 'koi_fpflag_co'),\n",
       " (0.1005591447319951, 'koi_fpflag_nt'),\n",
       " (0.05999362312736498, 'koi_fpflag_ss'),\n",
       " (0.05809158514145868, 'koi_prad'),\n",
       " (0.05566752470422089, 'koi_model_snr'),\n",
       " (0.04020171602339959, 'koi_fpflag_ec'),\n",
       " (0.0395528606115416, 'koi_duration_err2'),\n",
       " (0.034302912424002574, 'koi_prad_err2'),\n",
       " (0.031703366812313005, 'koi_steff_err2'),\n",
       " (0.0312867265697172, 'koi_duration_err1')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can weight the features by their importance for more tuning purpose\n",
    "sorted_features=sorted(zip(model5.feature_importances_, X.columns), reverse=True)[:10]\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Importance Level')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Can be visualized in bar graph for analysis reason (feature weight)\n",
    "ax=pd.DataFrame(sorted_features).plot.bar(x=1,y=0, rot=45, title=\"Feature Importance\")\n",
    "ax.set_xlabel(\"Features Name\")\n",
    "ax.set_ylabel(\"Importance Level\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerunning Models by using top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new features based on sorted features\n",
    "X1 = df[['koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'SVM.sav'\n",
    "joblib.dump(your_model, 'SVM.sav')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
