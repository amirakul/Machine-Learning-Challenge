{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/jildiz/opt/anaconda3/lib/python3.8/site-packages (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/jildiz/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-81</td>\n",
       "      <td>0.11600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.60</td>\n",
       "      <td>76.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-176</td>\n",
       "      <td>0.03410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.46</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>-174</td>\n",
       "      <td>0.00537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-211</td>\n",
       "      <td>0.04200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>40.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-232</td>\n",
       "      <td>0.06730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.63400</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-152</td>\n",
       "      <td>0.63400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.35</td>\n",
       "      <td>453.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01740</td>\n",
       "      <td>-2.57</td>\n",
       "      <td>-166</td>\n",
       "      <td>0.01740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.22900</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-220</td>\n",
       "      <td>0.22900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.16200</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-236</td>\n",
       "      <td>0.16200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.28300</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-225</td>\n",
       "      <td>0.28300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_disposition  koi_fpflag_co  koi_fpflag_nt  koi_fpflag_ss  koi_prad  \\\n",
       "0          CONFIRMED              0              0              0      2.83   \n",
       "1     FALSE POSITIVE              0              0              1     14.60   \n",
       "2     FALSE POSITIVE              0              0              1     33.46   \n",
       "3          CONFIRMED              0              0              0      2.75   \n",
       "4          CONFIRMED              0              0              0      2.77   \n",
       "...              ...            ...            ...            ...       ...   \n",
       "6986  FALSE POSITIVE              0              0              0      1.11   \n",
       "6987  FALSE POSITIVE              1              0              1     29.35   \n",
       "6988       CANDIDATE              0              0              0      0.72   \n",
       "6989  FALSE POSITIVE              1              0              0      1.07   \n",
       "6990  FALSE POSITIVE              1              0              0      1.05   \n",
       "\n",
       "      koi_model_snr  koi_fpflag_ec  koi_duration_err2  koi_prad_err2  \\\n",
       "0              25.8              0           -0.11600          -0.19   \n",
       "1              76.3              0           -0.03410          -1.31   \n",
       "2             505.6              0           -0.00537          -2.83   \n",
       "3              40.9              0           -0.04200          -0.35   \n",
       "4              40.2              0           -0.06730          -0.30   \n",
       "...             ...            ...                ...            ...   \n",
       "6986            8.4              1           -0.63400          -0.23   \n",
       "6987          453.3              0           -0.01740          -2.57   \n",
       "6988           10.6              0           -0.22900          -0.08   \n",
       "6989           12.3              0           -0.16200          -0.11   \n",
       "6990            8.2              1           -0.28300          -0.12   \n",
       "\n",
       "      koi_steff_err2  koi_duration_err1  \n",
       "0                -81            0.11600  \n",
       "1               -176            0.03410  \n",
       "2               -174            0.00537  \n",
       "3               -211            0.04200  \n",
       "4               -232            0.06730  \n",
       "...              ...                ...  \n",
       "6986            -152            0.63400  \n",
       "6987            -166            0.01740  \n",
       "6988            -220            0.22900  \n",
       "6989            -236            0.16200  \n",
       "6990            -225            0.28300  \n",
       "\n",
       "[6991 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making you dataframe based on sorted features\n",
    "sorted_df=df[['koi_disposition','koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
    "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
    "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
    "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
    "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
    "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
    "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
    "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
    "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
    "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
    "       'koi_kepmag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new features based on sorted features\n",
    "X1 = df[['koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1= sorted_df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768901</td>\n",
       "      <td>7.380000e-05</td>\n",
       "      <td>-7.380000e-05</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>...</td>\n",
       "      <td>-171</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733726</td>\n",
       "      <td>6.060000e-06</td>\n",
       "      <td>-6.060000e-06</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>...</td>\n",
       "      <td>-175</td>\n",
       "      <td>4.578</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652707</td>\n",
       "      <td>6.540000e-05</td>\n",
       "      <td>-6.540000e-05</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>...</td>\n",
       "      <td>-189</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.953547</td>\n",
       "      <td>1.910000e-05</td>\n",
       "      <td>-1.910000e-05</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>4.536</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959319</td>\n",
       "      <td>5.150000e-07</td>\n",
       "      <td>-5.150000e-07</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>-77</td>\n",
       "      <td>4.359</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "6122              0              0              0              0    6.768901   \n",
       "6370              0              1              0              1    0.733726   \n",
       "2879              1              0              0              0    7.652707   \n",
       "107               0              0              0              0    7.953547   \n",
       "29                0              0              0              0    4.959319   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "6122     7.380000e-05    -7.380000e-05   133.077240          0.008440   \n",
       "6370     6.060000e-06    -6.060000e-06   132.020050          0.007950   \n",
       "2879     6.540000e-05    -6.540000e-05   134.460380          0.006190   \n",
       "107      1.910000e-05    -1.910000e-05   174.662240          0.001820   \n",
       "29       5.150000e-07    -5.150000e-07   172.258529          0.000083   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "6122         -0.008440  ...            -171      4.327           0.153   \n",
       "6370         -0.007950  ...            -175      4.578           0.033   \n",
       "2879         -0.006190  ...            -189      4.481           0.050   \n",
       "107          -0.001820  ...             -85      4.536           0.056   \n",
       "29           -0.000083  ...             -77      4.359           0.110   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "6122          -0.187     1.125          0.310         -0.207  294.40472   \n",
       "6370          -0.187     0.797          0.211         -0.056  284.50391   \n",
       "2879          -0.200     0.963          0.290         -0.097  295.50211   \n",
       "107           -0.016     0.779          0.023         -0.049  291.15878   \n",
       "29            -0.110     1.082          0.173         -0.130  292.16705   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "6122  39.351681      14.725  \n",
       "6370  42.463860      15.770  \n",
       "2879  38.983540      13.099  \n",
       "107   40.750271      15.660  \n",
       "29    48.727589      15.263  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3060</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-171</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2820</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-175</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>254.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-189</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0595</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-85</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>696.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-77</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_co  koi_fpflag_nt  koi_fpflag_ss  koi_prad  koi_model_snr  \\\n",
       "6122              0              0              0      1.24           10.8   \n",
       "6370              0              0              1      0.86           13.8   \n",
       "2879              0              1              0      3.21          254.3   \n",
       "107               0              0              0      2.25           38.4   \n",
       "29                0              0              0     12.21          696.5   \n",
       "\n",
       "      koi_fpflag_ec  koi_duration_err2  koi_prad_err2  koi_steff_err2  \\\n",
       "6122              0            -0.3060          -0.23            -171   \n",
       "6370              1            -0.2820          -0.06            -175   \n",
       "2879              0             0.0000          -0.32            -189   \n",
       "107               0            -0.0595          -0.14             -85   \n",
       "29                0            -0.0075          -1.46             -77   \n",
       "\n",
       "      koi_duration_err1  \n",
       "6122             0.3060  \n",
       "6370             0.2820  \n",
       "2879             0.0000  \n",
       "107              0.0595  \n",
       "29               0.0075  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale  new data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler1 = MinMaxScaler().fit(X_train1)\n",
    "X_train_scaled1 = X_scaler1.transform(X_train1)\n",
    "X_test_scaled1 = X_scaler1.transform(X_test1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model with SVC(different kernels)\n",
    "\n",
    "## 1. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8455082967766546\n",
      "Testing Data Score: 0.8415331807780321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model1 = SVC(kernel='linear')\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {model1.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model1.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8176616440968911\n",
      "Testing Data Score: 0.8203661327231121\n"
     ]
    }
   ],
   "source": [
    "#Testing linear model with sorted features\n",
    "from sklearn.svm import SVC \n",
    "tuned_model1 = SVC(kernel='linear')\n",
    "tuned_model1.fit(X_train_scaled1, y_train1)\n",
    "print(f\"Training Data Score: {tuned_model1.score(X_train_scaled1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {tuned_model1.score(X_test_scaled1, y_test1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.831012778943353\n",
      "Testing Data Score: 0.8255148741418764\n"
     ]
    }
   ],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "model2 = SVC(kernel='rbf')\n",
    "model2.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8148006866297921\n",
      "Testing Data Score: 0.8192219679633868\n"
     ]
    }
   ],
   "source": [
    "#Testing RBF model with sorted features\n",
    "from sklearn.svm import SVC \n",
    "tuned_model2 = SVC(kernel='rbf')\n",
    "tuned_model2.fit(X_train_scaled1,y_train1)\n",
    "print(f\"Training Data Score: {tuned_model2.score(X_train_scaled1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {tuned_model2.score(X_test_scaled1, y_test1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.846271218767881\n",
      "Testing Data Score: 0.8386727688787186\n"
     ]
    }
   ],
   "source": [
    "model3 = SVC(kernel='poly')\n",
    "model3.fit(X_train_scaled,y_train)\n",
    "print(f\"Training Data Score: {model3.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model3.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8394049208468434\n",
      "Testing Data Score: 0.830091533180778\n"
     ]
    }
   ],
   "source": [
    "#Testing Poly model with sorted features\n",
    "tuned_model3 = SVC(kernel='poly')\n",
    "tuned_model3.fit(X_train_scaled1,y_train1)\n",
    "print(f\"Training Data Score: {tuned_model3.score(X_train_scaled1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {tuned_model3.score(X_test_scaled1, y_test1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501144164759725"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "model4 = clf.fit(X_train, y_train)\n",
    "model4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8506864988558352"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing Decision Tree model with sorted features\n",
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "sorted_model4 = clf1.fit(X_train1, y_train1)\n",
    "sorted_model4.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958810068649885"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "model5 = rf.fit(X_train, y_train)\n",
    "model5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953089244851259"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing RandomForest model with sorted features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1 = RandomForestClassifier(n_estimators=100)\n",
    "sorted_model5 = rf1.fit(X_train1, y_train1)\n",
    "sorted_model5.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.617776082395575\n",
      "Testing Data Score: 0.5909610983981693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model6 = LogisticRegression()\n",
    "model6.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {model6.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model6.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8603852756055693\n",
      "Testing Data Score: 0.851258581235698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Testing LogisticRegression model with sorted features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sorted_model6 = LogisticRegression()\n",
    "sorted_model6.fit(X_train1, y_train1)\n",
    "print(f\"Training Data Score: {sorted_model6.score(X_train1, y_train1)}\")\n",
    "print(f\"Testing Data Score: {sorted_model6.score(X_test1, y_test1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.804\n",
      "k: 3, Train/Test Score: 0.910/0.831\n",
      "k: 5, Train/Test Score: 0.889/0.832\n",
      "k: 7, Train/Test Score: 0.880/0.830\n",
      "k: 9, Train/Test Score: 0.874/0.830\n",
      "k: 11, Train/Test Score: 0.869/0.831\n",
      "k: 13, Train/Test Score: 0.865/0.826\n",
      "k: 15, Train/Test Score: 0.861/0.824\n",
      "k: 17, Train/Test Score: 0.860/0.824\n",
      "k: 19, Train/Test Score: 0.856/0.830\n",
      "k: 21, Train/Test Score: 0.856/0.834\n",
      "k: 23, Train/Test Score: 0.854/0.831\n",
      "k: 25, Train/Test Score: 0.848/0.832\n",
      "k: 27, Train/Test Score: 0.844/0.832\n",
      "k: 29, Train/Test Score: 0.845/0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize\n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.824\n",
      "k: 3, Train/Test Score: 0.912/0.840\n",
      "k: 5, Train/Test Score: 0.892/0.843\n",
      "k: 7, Train/Test Score: 0.885/0.848\n",
      "k: 9, Train/Test Score: 0.884/0.847\n",
      "k: 11, Train/Test Score: 0.882/0.852\n",
      "k: 13, Train/Test Score: 0.878/0.848\n",
      "k: 15, Train/Test Score: 0.878/0.850\n",
      "k: 17, Train/Test Score: 0.874/0.844\n",
      "k: 19, Train/Test Score: 0.874/0.850\n",
      "k: 21, Train/Test Score: 0.872/0.848\n",
      "k: 23, Train/Test Score: 0.872/0.853\n",
      "k: 25, Train/Test Score: 0.872/0.852\n",
      "k: 27, Train/Test Score: 0.871/0.850\n",
      "k: 29, Train/Test Score: 0.872/0.851\n"
     ]
    }
   ],
   "source": [
    "#Testing KNN model with sorted features\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores1 = []\n",
    "test_scores1 = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled1, y_train1)\n",
    "    train_score1 = knn.score(X_train_scaled1, y_train1)\n",
    "    test_score1 = knn.score(X_test_scaled1, y_test1)\n",
    "    train_scores1.append(train_score1)\n",
    "    test_scores1.append(test_score1)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score1:.3f}/{test_score1:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwdVf3/8dc7S9N0TShtadOkC9SWUqCBCiKLLCqLKJUvCPgVEBdARcWFVb+KK/wEFbeviIqg7MqqgMhXWQRR6F66QWnpku50X9Mkn98f56SZ3t4kN2lubpbP8/G4j3vvmZkzZ+4ynznnzMyRmeGcc861VF6uC+Ccc65z8gDinHOuVTyAOOecaxUPIM4551rFA4hzzrlW8QDinHOuVTyAdECStkgaletyuK5J0luS3pvrcrQ3Sc9J+lSuy9GVeABpobhzr3/USdqeeP/frchvrx+1mfUxs4VtV+q91vlxSSbpI9laR65JOk7SvyRtlLRO0kuS3pnjMt0pqTr+VjZLmiLpPbksUza15XcgaUT8zRa0dTlj/jdI2pXy/766DfK8u63K2BF5AGmhuHPvY2Z9gCXABxNp9+S6fBm6GFgXn9tNtv78adbTD/gL8DNgP6AM+Baws43Xk9+KxX4Qfzv9gV8CD7cynw6tLb+D9vrdAA8k/99m9oN2Wm9a7bjdrWdm/mjlA3gLeG98nQdcC7wJvA08COwXp/UE7o7pG4BXgcHA94BaYAewBfh5nN+Ag+LrO4FfAE8Am4H/AAcmyvB+YD6wEfhf4HngU02UeThQB/wXUAMMTkzLB66P27AZmAKUx2mHAM8QAs8q4PpE+b6byONEYFnKZ3QNMJOw8yhIfE6bgTnAh1PK+GlgbmL6EcBVwEMp8/0MuDXNNk4ENjTz3e21jph+MPBc/J5mAx9KLHMnYaf/JLAVeC8wFHgIWAMsAr7QxDpTP6te8bseGt8fCPwj/k7WAvcAJYn5rwGqYpnnA6c099uL0y8EFsdpXyPxu01Txv7A7+P2LAa+DuTFaR8HXgRuAdbH7T29kXya/A5imb8e17E6rrN/nDYifi6fJBykvRCfjfA/2QIcE+f9RPwe1wNPA8MT63gfMI/w3/g5Tfw3gBuAuxuZ1tQ6fgIsBTYR/i/Hx/TTgGpgVyzvjNR9Rup60213U+sHBPw4fn4bCf+x8e26D2zPlXW1B3sGkCuBfwPDgCLgV8B9cdplwJ8JO4x84EigX5z2XOqPmr0DyDrgKMLO9x7g/jht//jDPTtO+2L8wTYVQP4HeCW+ngV8OTHtqpg2Jv44DwcGAH2BFcBXCMGwL3B0onzNBZDpQDlQHNPOJex484DzCDvjIYlpVcA7YxkOIgS9IXG+kjhfQfzjHJlmG/sRdpZ3AacDpSnTG1tHIbCAEER7ACcTdtZjEtu6ETg2lr0XYafxjTj/KGAhcGojn/3uzyr+Di6P8+fHtIMIO70iYCBhx3lrnDaGsKOqDzYjiAcSNP3bG0fYgZ0Qp/2IcODQWAD5PfBY/I5HAK8Dn4zTPk74fX06lv8zwHJArfgOPhE/61FAH+Bh4A+JbbNYlt5AcSKtIJHHpJjHwfH38HXgXyn/jXPi9/qluN0tCiBNrSNO/xjhP1JA+H+sBHo2lieZBZDkdje1jacSfn8lhN/xwcT/UbvtA9tzZV3twZ4BZC7xiDC+HxL/bAXxz/Iv4LA0eTyX+qNm7wDym8S0M4B58fVFwMuJaSLsZJoKIG8AV8bX1xGPjOL7+cBZaZa5AJjWSH530nwA+UQzn+P0+vUSjrC+2Mh8TwGfjq/PBOY0kefBsWzL4o7jcWJtq7F1AMfHHUBeIu0+4IbEtv4+Me1oYElKHtcBv2vis9pBqN3siI//bmIbJtV/7oTgsppQ6ylMma+p3943iAcccVpvwpHxXgGEEBR2AuMSaZcBz8XXHwcWJKbV16AOaMV38Hfgs4l5xyTKPCLmOyoxvT4tGUCeIga3+D4P2EY4GLgI+HfKf2MZTQeQ6vjd1D+GNrWORvJZDxyeyLM1AWRUhtt4MiHAv4vEb7Y9H94H0naGA49I2iBpA+FPXUtoqvoDYad1v6Tlkn4gqbAFea9MvN5GOGKD8ANfWj/Bwi9sWWOZSDoWGAncH5PuBQ6VNCG+Lyc0g6RqLD1TS5NvJF0kaXrisxpPOGJsbl13EY74iM9/aGyFZjbXzD5uZsNi/kOBW5tZx1BgqZnVJdIWE9rv023LcGBo/XbEbbme8J035hYzKyEcXU4EbpZ0OoCkQZLul1QlaROh2XP/uD0LCDWNG4DVcb6hiXI09ttL/Y1sJdQM0tmfUJNa3MT27/4tmtm2+LIPaTTzHQxNs54C9vzs9vjdpDEc+Eliu9cRAkUZ6f8bzeX3oJmVJB7Lm1kHkr4iaW48UWADoQlw/0bXkJnU31ja9ZvZPwhNc78AVkm6PfY9tRsPIG1nKaE9OPkD7GlmVWa2y8y+ZWbjgHcTjp4visvZPqxzBaHZAgBJSr5P42LCj2+6pJWE/hQSZVlKaIdP1Vg6hGalXon3B6SZZ/c2ShoO/Bq4AhgQd6avxXI1t65HgcMkjSd8hhmdtGBm8whHwuObWcdyoFxS8n9RQWju2mtbYj6LUr7zvmZ2RgZlMjN7DXgJ+EBMvjHmf5iZ9SMESSWWudfMjiPsVAz4f4lypP3tEX4j5fV5SOpFaHJJZy2hFjC8ie1vlTTfQf3OObmeGkL/2u7FGnldbylwWcp2F5vZv9h7u5V83wKNrkPS8YR+qY8QmuhKCE2c9d9ZujK36P/SzDZiZj81syMJfZTvIDRDtxsPIG3nNuB7cQeJpIGSzoqvT5J0aDzbZhPhT1obl1tFaAdujScINYhJ8YyNz5H+B4mknoQf+qXAhMTj88B/x+V/A3xH0mgFh0kaQDib5gBJV0oqktRX0tEx6+nAGZL2k3QA4Si5Kb0Jf5A1sVyX0LBTIZbhq5KOjGU4qP4zNbMdwJ8INadXzGxJI9s6Nh4ZDovvywnNcP9uZh3/IfzBr5ZUKOlE4IM01NhSvQJsknSNpGJJ+ZLGZ3qqqqSxwHGEznoI/Q5bgA2SykjsDCSNkXSypCJC09d2Gn5Djf724ud1ZjyltgfwbRr535tZLaED/nvxOx4OfJlQE2qRDL6D+4AvSRopqQ/wfcJZUDWNZLmGcPJH8r9yG3CdpEPiOvpLOjdOewI4RNLZ8bf9BRr5bzSjqXX0JQS9NUCBpG8Q+n7qrQJGpByQTAfOj7+viYQ+mlatX9I7JR0dWzO2En4XtY1nlQW5aDfrKg/2Pgvry4R+hM2EJpLvx2kXxPSthB/VT4ltucAxhHbM9cBPY1pqH0hTfQynxeXrz8J6GbgwTVnPJxyVpbaf9yQceZ5JaAP/OuHsms2Es8WGxfnGE9qt1xOaMa5NLP8AITDOJHRWpvaBvDdlnd8jVMXXEjp19zg7htC5PJ+wM30NqExMOy5+Ppc08b2UEXaEVfEzryJ0LPdrbh2EI7nn4+e5xxliqd9FTBtK2BmujJ/Nv1O3N2X56rjOrYQzbb5Pw1lOhxA6RbcQdjRfqf8sgcMIAWtz/Oz+QkOHeqO/vTj94riuTM7CKiUEjDWEo99vkHIWVsr8u3+rLfkOYpm/EdexJq6zNE4bQUp/R0z/dpx3A/CumHYh4cSPTTGvOxr5b+zLWVhp10H4v/w2pq8ArmbPfcIAwllr64GpMW0U4UBlCyHI/ZS9+0BSt7ux9Z9C+M9toeGsvT7tuQ9ULIjrAuKRzjJCx+yzuS5PNkiqIJyaeYCZbcp1eZzrzrwJq5OTdKqkkti0cT2h/fXfzSzWKcUA+WXCWUUePJzLsY5/paNrzjGEPoEehCaXSWa2PbdFanuSehOa/xYTmiaccznmTVjOOedaxZuwnHPOtUq3aMLaf//9bcSIEbkuhnPOdSpTpkxZa2YDG5veLQLIiBEjmDx5cq6L4ZxznYqkxU1N9yYs55xzreIBxDnnXKt4AHHOOdcqHkCcc861igcQ55xzrZK1ACLpDkmrJb3WyHRJ+qmkBZJmSjoiMe00SfPjtGsT6ftJekbSG/G5NFvlf3RaFcfe9A9GXvsEx970Dx6dts93tHbOuS4lmzWQO2n6lhOnA6Pj41LCWNPEW57/Ik4fB1wgaVxc5lrg72Y2mnBn2GtTM20Lj06r4rqHZ1G1YTsGVG3YznUPz/Ig4pxzCVkLIGb2AuG20405izA8qJnZv4ESSUMIY38vMLOFZlZNGIvhrMQyd8XXdxGG/GxzNz89n+279ryt/vZdtdz89PxsrM455zqlXPaBlLHn0I3LYlpj6RDGU14BEJ8HNZa5pEslTZY0ec2aNS0q2PIN6e9F2Fi6c851R7kMIEqTZk2kt4iZ3W5mE81s4sCBjV6Jn9bQkuIWpTvnXHeUywCyjD3HKB5GGCe5sXQIA8cPAYjPq7NRsKtOHUNxYf4eacWF+Vx16phsrM455zqlXAaQx4GL4tlY7wI2xmapV4HRcazkHoShWB9PLHNxfH0x8Fg2Cjapsowbzz6UsljjKC7M58azD2VSZVkzSzrnXPeRtZspSrqPMH73/pKWAd8ECgHM7DbgSeAMYAGwDbgkTquRdAXwNGHM4TvMbHbM9ibgQUmfJIzxfC5ZMqmyjEmVZXzm7im8tnyjBw/nnEuRtQBiZhc0M92AzzUy7UlCgElNf5swkHy7qawo4anXVrJm804G9i1qz1U751yH5leiN6OyIlyrOH3phhyXxDnnOhYPIM0YP7Q/BXli2pL1uS6Kc851KB5AmlHcI5+Dh/Rj2hKvgTjnXJIHkAxUVpQwY9kGautafDmKc851WR5AMlBZUcK26lpeX7U510VxzrkOwwNIBirLQ0e6N2M551wDDyAZGD6gF6W9Cr0j3TnnEjyAZEASlRWlTPNTeZ1zbjcPIBmqLC9hweotbNy+K9dFcc65DsEDSIbqLyic4bUQ55wDPIBk7LDy/kjeke6cc/U8gGSoX89CRg/qw7Sl3pHunHPgAaRFKstLmbZkA+E+kM451715AGmByooSNm7fxaK1W3NdFOecyzkPIC1Q35Hu/SDOOecBpEUOGtSHPkUF3g/inHN4AGmR/DxxeHl/r4E45xweQFqssryUeSs3s626JtdFcc65nPIA0kKVFSXU1hmzlm3MdVGccy6nshpAJJ0mab6kBZKuTTO9VNIjkmZKekXS+Jg+RtL0xGOTpCvjtBskVSWmnZHNbUg1obwEwO+L5Zzr9gqylbGkfOAXwPuAZcCrkh43szmJ2a4HppvZhyWNjfOfYmbzgQmJfKqARxLL/djMbslW2ZsyoE8Rwwf0Yrr3gzjnurls1kCOAhaY2UIzqwbuB85KmWcc8HcAM5sHjJA0OGWeU4A3zWxxFsvaIpXlJUxdst4vKHTOdWvZDCBlwNLE+2UxLWkGcDaApKOA4cCwlHnOB+5LSbsiNnvdIak03colXSppsqTJa9asae02pFVZUcrqzTtZsXFHm+brnHOdSTYDiNKkpR6y3wSUSpoOfB6YBuw+vUlSD+BDwB8Ty/wSOJDQxLUC+GG6lZvZ7WY20cwmDhw4sNUbkU5lRewH8WYs51w3ls0AsgwoT7wfBixPzmBmm8zsEjObAFwEDAQWJWY5HZhqZqsSy6wys1ozqwN+TWgqa1djD+hHUUGej1DonOvWshlAXgVGSxoZaxLnA48nZ5BUEqcBfAp4wcw2JWa5gJTmK0lDEm8/DLzW5iVvRo+CPA4t6+9nYjnnurWsnYVlZjWSrgCeBvKBO8xstqTL4/TbgIOB30uqBeYAn6xfXlIvwhlcl6Vk/QNJEwjNYW+lmd4uKitKuOvlxVTX1NGjwC+ncc51P1kLIABm9iTwZErabYnXLwOjG1l2GzAgTfqFbVzMVqmsKOXX/1zE3BWbODxeG+Kcc92JHzq3UkNHuveDOOe6Jw8grTSkfzEH9Ovp/SDOuW7LA8g+qKwo8VN5nXPdlgeQfVBZUcKSddtYu2VnrovinHPtzgPIPqgfodDvi+Wc6448gOyD8UP7U5AnH6HQOdcteQDZB8U98jl4SD/vB3HOdUseQPZRZUUJM5ZuoLbO78zrnOtePIDso8qKErZW1/LG6s25LopzzrWrjAKIpOGS3htfF0vqm91idR6V5aEj3ZuxnHPdTbMBRNKngT8Bv4pJw4BHs1mozmT4gF6U9ir0K9Kdc91OJjWQzwHHApsAzOwNYFA2C9WZSKKyotRrIM65bieTALIzDkkLgKQC9h4YqlurLC/hjdVb2Lh9V66L4pxz7SaTAPK8pOuBYknvI4wO+OfsFqtzqb+gcOYyr4U457qPTALINcAaYBZh7I0nga9ns1CdzWHl/ZG8I9051700OR6IpDxgppmNJwwf69Lo17OQ0YP6eEe6c65babIGEscdnyGpop3K02lVlpcybekGzLx7yDnXPWTShDUEmC3p75Ier39ku2CdTWVFCRu27eKtt7fluijOOdcuMhnS9ltZL0UXUN+RPm3Jekbu3zvHpXHOuexrtgZiZs8D84C+8TE3pjVL0mmS5ktaIOnaNNNLJT0iaaakVySNT0x7S9IsSdMlTU6k7yfpGUlvxOfSTMqSbQcN6kOfogLvSHfOdRuZXIn+EeAV4FzgI8B/JJ2TwXL5wC+A04FxwAWSxqXMdj0w3cwOAy4CfpIy/SQzm2BmExNp1wJ/N7PRwN/j+5zLzxOHl/f3W7s757qNTPpAvga808wuNrOLgKOA/8lguaOABWa2MF6IeD9wVso84whBADObB4yQNLiZfM8C7oqv7wImZVCWdlFZXsrcFZvZXl2b66I451zWZRJA8sxsdeL92xkuVwYsTbxfFtOSZgBnA0g6ChhOuNcWhKvd/yZpiqRLE8sMNrMVAPG5w9xWpbKihNo6Y1bVxlwXxTnnsi6TTvS/SnoauC++Pw94KoPllCYt9RzXm4CfSJpOuFBxGlATpx1rZsslDQKekTTPzF7IYL1h5SHoXApQUdE+ZyFPKC8BQkf6USP3a5d1OudcrjQbQMzsKklnA8cRgsLtZvZIBnkvA8oT74cBy1Py3gRcAiBJwKL4wMyWx+fVkh4hNIm9AKySNMTMVkgaAiRrR8m8bwduB5g4cWK7XJwxoE8Rwwf08o5051y3kEkn+kjgSTP7spl9iVAjGZFB3q8CoyWNlNQDOB/Y4/oRSSVxGsCngBfMbJOk3vVjjkjqDbwfeC3O9zhwcXx9MfBYBmVpN5XlJUxdst4vKHTOdXmZ9GX8EahLvK+NaU0ysxrgCuBpYC7woJnNlnS5pMvjbAcTLlKcRzhb64sxfTDwoqQZhDPAnjCzv8ZpNwHvk/QG8L74vsOorChl9eadrNi4I9dFcc65rMqkD6QgeTt3M6tO1BqaZGZPEm6+mEy7LfH6ZWB0muUWAoc3kufbwCmZrD8XKivq+0E2MLSkOMelcc657MmkBrJG0ofq30g6C1ibvSJ1bmMP6EdRQZ7fWNE51+VlUgO5HLhH0s8JnehLCRf9uTR6FORxaFl/pi31jnTnXNeWyVlYbwLvktQHkJltzn6xOrfKihLuenkx1TV19CjIpJLnnHOdT6N7N0kflDQ8kfRlQsf24/HMLNeIyopSqmvqmLtiU66L4pxzWdPU4fH3CCMRIulM4GPAJwin0d7WxHLdXkNHuveDOOe6rqYCiJlZ/eAWZwO/NbMpZvYbYGD2i9Z5DelfzAH9eno/iHOuS2sqgEhSnzis7SnEmx5GPbNbrM6vsqLEr0h3znVpTQWQW4HpwGTCGCCTASRVAivaoWydWmVFCUvWbWPtlp25LopzzmVFowHEzO4A3gN8EjgjMWkl8f5VrnH1IxRO91qIc66LavIcUzOrMrNpZlaXSFthZkuyX7TObfzQ/hTkyQeYcs51WX6RQpYU98jn4CH9vB/EOddleQDJosqKEmYs3UBtnd+Z1znX9WRyO/dbJB3SHoXpaiorSthaXcsbq/3ifedc15NJDWQecLuk/8RbsffPdqG6isry0JHuzVjOua6o2QBiZr8xs2MJN1AcAcyUdK+kk7JduM5u+IBelPYq9CvSnXNdUkZ9IJLygbHxsRaYAXxZ0v1ZLFunJ4nKilKvgTjnuqRM+kB+BMwnXAvyfTM70sz+n5l9EKjMdgE7u8ryEt5YvYWN23fluijOOdemMqmBvAYcZmaXmdkrKdOOykKZupT6CwpnLvNaiHOua8kkgKwHCuvfSCqRNAnAzDZmq2BdxWHl/ZG8I9051/VkEkC+mQwUZrYB+GYmmUs6TdJ8SQskXZtmeqmkRyTNlPSKpPExvVzSs5LmSpot6YuJZW6QVCVpenyckZpvR9KvZyGjB/XxjnTnXJeTSQBJN0+zIxnGjvdfAKcD44ALJI1Lme16YLqZHUY4y+snMb0G+IqZHQy8C/hcyrI/NrMJ8fFkBtuQU5XlpUxbugEzv6DQOdd1ZBJAJkv6kaQDJY2S9GNgSgbLHQUsMLOFZlYN3A+clTLPOOJt4s1sHjBC0uB4v62pMX0zMBcoy3CbOpzKihI2bNvFW29va35m55zrJDIJIJ8HqoEHgD8CO4DPZbBcGbA08X4ZeweBGYTBqpB0FDAcGJacQdIIwtle/0kkXxGbve6QVJpBWXKqviPdm7Gcc11JJhcSbjWza81sYjyF9zoz25pB3kqXXcr7m4BSSdMJgWoaofkqZCD1AR4CrjSz+gHGfwkcCEwgjEvyw7Qrly6VNFnS5DVr1mRQ3Ow5aFAf+hQVeEe6c65LyaQvYyBwNXAIiZEIzezkZhZdBpQn3g8DlidniEHhkrgeAYviA0mFhOBxj5k9nFhmVaJsvwb+km7lZnY7cDvAxIkTc9r5kJ8nDi/v77d2d851KZk0Yd1DuB/WSOBbwFvAqxks9yowWtJIST2A84HHkzPEU4J7xLefAl4ws00xmPyWMBLij1KWGZJ4+2HCdSodXmV5KXNXbGZ7dW2ui+Kcc20ikwAywMx+C+wys+fN7BOEM6OaZGY1wBXA04RO8AfNbHa8IePlcbaDgdmS5hHO1qo/XfdY4ELg5DSn6/5A0ixJM4GTgC9luK05VVlRQm2dMavKL51xznUNzTZhAfX34Fgh6QOEZqhhTcy/WzzF9smUtNsSr18GRqdZ7kXS96FgZhdmsu6OZkJ5CRA60o8auV+OS+Occ/sukwDy3XgL968APwP60UmO+juSAX2KGD6gl3ekO+e6jCYDSLwYcLSZ/QXYSGgycq1UWV7Cv958GzMjdPM451zn1WQfiJnVAh9qp7J0eZUVpazevJMVG3fkuijOObfPMmnC+peknxMuJNx9/Uf9leIuc5UV9f0gGxhaUpzj0jjn3L7JJIC8Oz5/O5FmQHPXgbgUYw/oR1FBHtOWrOcDhw1pfgHnnOvAmg0gZub9Hm2kR0Eeh5b1Z9pS70h3znV+mVyJ/o106Wb27XTprmmVFSXc9fJiqmvq6FGQ0YjCzjnXIWWyB9uaeNQSLvgbkcUydWm7auuorqljzNef4tib/sGj06pyXSTnnGuVTJqw9rhZoaRbSLklicvMo9OquP+VcINiA6o2bOe6h2cBMKmy096t3jnXTbWmDaUXMKqtC9Id3Pz0fHbU1O2Rtn1XLTc/PT9HJXLOudbLpA9kFg23Yc8HBrLnGVkuQ8s3bG9RunPOdWSZnMZ7ZuJ1DbAq3ijRtdDQkmKq0gSLA/r3TDO3c851bJk0YQ0B1pnZYjOrAnpKOjrL5eqSrjp1DMWF+Xul9+6R77d5d851OpkEkF8CWxLvt8U010KTKsu48exDKSspRkBZSTEfe1cFb67dyqV/mMyOXR5EnHOdRyZNWDKz3SP6mVmdpEyWc2lMqizb64yrCeWlXPWnGVz2hyncftGRFBXsXUtxzrmOJpMayEJJX5BUGB9fBBZmu2DdyTlHDuOmsw/l+dfX8Jm7p7KzxmsizrmOL5MAcjnhflhVhHHOjwYuzWahuqPz3lnB9z98KP+Yt5or7p1Gdcrpvs4519FkciHhasJ45i7LPnp0BTV1dXzjsdl84b5p/OyjlRTm++1OnHMdU7N7J0l3SSpJvC+VdEd2i9V9XXTMCL5x5jj+OnslVz4wnZpar4k45zqmTDrDDzOz3bePNbP1kiqzWKZu7xPHjaTOjO8+MZd8iR+fN4H8PB/B0DnXsWTSPpInqbT+jaT9yCzwIOk0SfMlLZB0bZrppZIekTRT0iuSxje3rKT9JD0j6Y34XJqab1fwqeNHcc1pY3l8xnKu+uMMauus+YWcc64dZRJAfkgYlfA7kr4D/Au4ubmF4njqvyDcvXcccIGkcSmzXQ9MN7PDgIuAn2Sw7LXA381sNPD3+L5L+syJB/LV97+Dh6dVcc1DM6nzIOKc60Ay6UT/vaTJhBEIBZxtZnMyyPsoYIGZLQSQdD9wFpBcdhxwY1zPPEkjJA0m3KyxsWXPAk6My98FPAdck0F5OqUrTh5NTZ1x6/+9QUGe+P6HDyXPm7Occx1ARk1RMWDMkXQgoTbwoJmNb2axMmBp4n39KcBJM4CzgRclHQUMB4Y1s+xgM1sRy7VC0qB0K5d0KfF044qKimaK2rF98ZTR1NQaP392Afl54ruTxiN5EHHO5VYmZ2ENkXSlpFeA2YQ78l6QQd7p9nCpbTA3AaWSpgOfB6YRbtiYybJNMrPbzWyimU0cOHBgSxbtcCTxlfe/g8vfcyD3/GcJNzw+m8TNAZxzLicarYFI+jQhUAwDHgQ+BTxmZt/KMO9lQHni/TBgeXIGM9sEXBLXJ2BRfPRqYtlVkobE2scQYHWG5enUJHHNaWOoravj1/9cRH5eHv9z5sFeE3HO5UxTTVi/AF4GPmpmkwEkteSw91VgtKSRhKvYzwc+mpwhXl+yzcyqCQHqBTPbJKmpZR8HLibUXi4GHmtBmTo1SVx/xsHU1Bl3vLSIgnxx3eljPYg453KiqQAyFDgX+FHs2H4QKMw0YzOrkXQF8DSh2esOM5st6fI4/TbgYOD3kmoJHeSfbGrZmPVNwIOSPgksiWXsNiTxjTPHUVNr3P7CQvLzxNWnjvEg4pxrd8qkLV3SMEIt4AJC89IjZnZ9lsvWZiZOnGiTJ0/OdeJ1nvMAACAASURBVDHaVF2d8fXHXuPe/yzhCycfxJffPybXRXLOdTGSppjZxMamZ3oW1jLgFuAWSWPwe2PlXF6e+O5Z46mtNX76jwW8vmoLs6o2snzDdoaWFHPVqWP2um28c861pRaP62Fm84FMO9JdFuXliRvPPpSFa7bw19krd6dXbdjOdQ/PAvAg4pzLGr/VayeXlyeqNu49zvr2XbXc/PT8HJTIOdddeADpAlZs2JE2vWrDdp6ctcKHynXOZUWzTViSjkiTvBFYbGY1bV8k11JDS4qp2rB3LSRP8Nl7ptK3qIDTxh/ApMoy3jVqgN/Z1znXJjLpA/lf4AhgJuEK8fHx9QBJl5vZ37JYPpeBq04dw3UPz2J7oqZRXJjP9yaNZ1C/njw6vYqnXlvJH6csY3C/Ij542FAmVZZxyNB+fvqvc67Vmj2NN97I8Dv112HEu+JeBXwHeNjMJmS9lPuoK57Gm+rRaVXc/PT8Rs/C2rGrlr/PXc2j06t4bv5qdtUaBw7szaQJZZw1oYyKAb1yWHrnXEfU3Gm8mQSQ6alBoj4t3bSOqDsEkJbYsK2aJ2et5NHpVbyyaB0AR1SUMKmyjA8cOoQBfYqA5oOSc65ra4sA8gCwDrg/Jp0H7A9cCLxoZu9so7JmjQeQxlVt2M7j05fz2PQq5q3cTEGeOH70/gwrLeaPU5axY1fDkLrFhfncePahHkSc6ybaIoAUA58FjiP0gbxI6BfZAfQysy1tV9zs8ACSmXkrN/HotOU8Pr2K5RvTn9k1uF8RT33xBHoX5VNUkN+q9XjNxrnOYZ8DSFfgAaRl6uqMA69/stn75xfmi149CuhTVEDvovw9XvfuUUDvogJ6FeXTJ77uXZTPnOWbuO+VpVTXes3GuY5un29lIulY4AbCYE+75zezUW1RQNfx5OWp0VODS3oVcuUpo9laXcuWnTVs21nDlp21bN1Zw9bqGrburGHN5p27X2/dWbtHsEhn+65arvrTDP4xbzXDSosp368X5aW9KN+vmKElxRTmZ3a5ktdsnGtfmZzG+1vgS8AUwK9I6yYaOzX4hg8e0uKdcnVNHduqa9iys4bj/9+zaWs2u2qNaUvX88SsFdQmxn7PEwzpX8yw0mKGxaASgkt4PbhvT/LyxKPTqvYor9/OxbnsyySAbDSzp7JeEteh1O902+KIvkdBHj0KelDSq0ejNZuykmL+efXJ1NTWsXLTDpau287S9dtYtm4bS9dvZ+m6bby0YC2rNu8g2eraIz+PstJilm/Yzs6aPWs69bdz8QDiXHZk0ol+E2FMjoeBnfXpZjY1u0VrO94H0nGk1hSgZX0gO2tqqVq/fXdQWbY+BJonZq5odJkrTjqI8WX9GV/Wj7KSYr940rkMtcXt3I+Oz8lMDDh5Xwrmuqd9rdkUFeQzamAfRg3ss0f69CX/SFuzKcgTv3z+zd3NYqW9CmMw6c+hZf0ZP7Q/5ft5UHGuNfwsLNclNFWzOW38AcxdsYnXlm/itWUbeW35Ruav3ExNDCr9ehbsDiiHxOfh+/UiL94zLBud897h7zqDVtdAJH3MzO6W9OV0083sR21RQOfaQnM1m8qKUiorSnfPv7OmltdXhkG4ZlVtZPbyjfzupbd2nzHWt6iAcUP7UVyYx0tvvs2u2hBsqjZs59qHZ7JzVy2TjiijMC9vd6DJlHf4u66i0RqIpMvM7FeSvplmspnZt7NbtLbjNRCXieqaOt5YvZnXqjbyWtUmZlVtZPrSDc0ul58nCvJEYX4eBfmiIC+PwnxRkC8K81LT8phVtZHqmr1PbR7cr4iXrz2lxQHJuWxpiyvRjzWzl5pLa2TZ04CfEDrhf2NmN6VM7w/cDVQQakO3mNnv4rC5DyRmHQV8w8xulXQD8GlgTZx2vZk92VQ5PIC41hp57RONXlD51fe/g121Rk1dHTW1tvv1rlqjpraOmjpjV22Ytju9ro6XFrzd6PqKC/N5xwF9GTu4L2OH9GXMAX0Ze0A/9uvdIzsb6FwT2qIT/WeE27k3l5a64nzgF8D7gGXAq5IeN7M5idk+B8wxsw9KGgjMl3RPHDZ3QiKfKuCRxHI/NrNbMii7c/ukqdOOrzh5dKvyPPam9B3+JcWFnH3EMOat3MQzc1fxwOSlu6cN6lvE2CH9GHtAX8YeEALLQYP67HU7mWz1rXifjUunqT6QY4B3AwNT+kH6EWoUzTkKWGBmC2N+9wNnAckAYkBfhVNg+hBu2pg6SNUpwJtmtjiDdTrXphq7oPKqU8e0eZ43fKjhIk0zY82WncxfuZl5KzYzb+Vm5q3cxJ3/ent381d+nhi1f+/dgWX9tmr+8PLi3dfD7GvfiplhBo9MW8bXHn1t9401vc/G1WuqBtKDsFMvAPom0jcB52SQdxmwNPF+GQ2nBNf7OfA4sDyu4zwzS20cPh+4LyXtCkkXAZOBr5jZ+tSVS7oUuBSgoqIig+I6t7e2vKCyJXlKYlDfngzq25PjRw/cnV5TW8dbb28NASUGlmlL1vPnGcvTrmv7rlq+8scZ3PK3+ZhBbZ1RZ/WP+D6m1ca0urqG6Y3ZvquWax+ayeTF6xjctyeD+hWF8sbnAb17ZNSX4zWbzi2TPpDh9Uf/kvKAPma2qdmMpXOBU83sU/H9hcBRZvb5xDznAMcCXwYOBJ4BDq/PX1IPQnA5xMxWxbTBwFpC7eU7wBAz+0RTZfE+ENfVbd6xi8Nu+Fuj/TVnV5aRlyfyFGoueQqP/DwhQb4UpzfMI4l8iR//3+uNrrekVyEbtu3aKz0/T+zfpweD+/VkUN8iBvbtyeD6INO3iEH9ipi2ZD03PjWvzYcM6GzNeB0537boA7lR0uWE+2BNAfpL+pGZ3dzMcsuA8sT7YYRgkHQJcJOFKLZA0iJgLPBKnH46MLU+eAAkX0v6NfCXDLbBuS6tb8/CJvtrfnRe68d9e3Dy0kbzfenak9lZU8uazTtZtWknazbvYPXmnazetJNVm8Lrqg07mL50A2u3VDe7rvoba973yhKKCvPpkZ9HUWEeRfE5vM+nqCBv97T6tB75ecxctoH7XllCdeK066sfmsmitVs5aewg8sQewTNP4eah+TEtL4+9A6vEU7NX8O0/z2nzZrxsndL9yNRlXPfIrKw3O2Y8IqGk/waOBK4BppjZYc0sVwC8TujDqAJeBT5aPzRunOeXwCozuyHWLKYSaiBr4/T7gafN7HeJZYaY2Yr4+kvA0WZ2flNl8RqI6w729TYx2c53V20da7c0BJdL/zCl0XmPHrkfO2vq2FlTR3VNbXyu2/28o6aWjnINdK8e+RTmx9O042nbhfl5FOSF07ZDevJ1w/Pzr69m+669T+nuWZDHuw/aP+1ZfOGMv3CWX/J16rzp1Af9TLVFDaRQUiEwCfi5me2S1OxXZ2Y1kq4AniZ0ut9hZrNjbQYzu43QBHWnpFmEwaquSQSPXoQzuC5LyfoHkiYQmrDeSjPduW4pG/01bZlvYX4eQ/oXM6R/MRB2Zo3VbB647Jgm8zIzaupsj6Cys6aWE29+rtFmvN99/J179AHV1pHoD0q8r4v9Q2aYGbV1xrf+PKeRXOGCoyqoqa1jV108fbvWdr9O3env2FVHTW3N7vR0wQNgR00dqzfv2CPY9CxsCEzJa456FOwduP73uTfT5rs8zee9LzIJIL8i7KhnAC9IGk7oSG9WvD7jyZS02xKvlwPvb2TZbcCANOkXZrJu57qjSZVlWemEzka++3KGmyQK4w6zd1FDelPNeCeNHdTqsv7mn4sazfd/zhzX6nwbO6W7rKSYv3z++Fbn+9j05WnzHVpS3Oo802l2pB4z+6mZlZnZGRYsBk5q01I457qdSZVl3Hj2oeEOyYSd5r42t1116hiKC/e8ymBfT7v2fBuXyYiEg4HvA0PN7HRJ44BjCANNOedcq7V1zaajN+N19nxTZdKJ/hTwO+BrZnZ47ByfZmaHtmlJssg70Z1zruWa60RvtAkrBgqA/c3sQaAOQuc4PrStc851e031gdRfi7FV0gDCWU9IehewMdsFc84517E11QdSfx+CLxNuN3KgpJeAgWR2KxPnnHNdWFMBJHkTxUcIp+OKMC76e4GZWS6bc865DqypAJJPuJli6h3RemWvOM455zqLpgLIis406qBzzrn21VQnuo+r6ZxzrlFNBZBT2q0UzjnnOp1GA4iZrWvPgjjnnOtcmr0XlnPOOZeOBxDnnHOt4gHEOedcq3gAcc451yoeQJxzXceLt8KiF/ZMW/RCSO+I+XZyHkBc1+B/cAdQdgT88ePhu6+tgYXPh/dlR7RdvhCe2yLfTi6TIW2d6/jq/+Dn3gkjT2j4g597Z27L5drPjo2wczNUHAO/nwQWR53IK4T7PwYFRVDQEwp6hOf8Hnu+LyiC/KI4X9HeaYecDfedDwe+FxY9D2f/JvzWOqIXbw3/iWT5Fr0AVVPhuCvbbDVZDSCSTgN+Qriv1m/M7KaU6f2Bu4GKWJZbzOx3cdpbwGbC2CM19YOaSNoPeAAYQRir/SNmtj6b2+E6ODPoPwwOOw/u/i/YfzSsewve920oPzrXpev82mln1GI11bDsVVj4HCx8FqqmgNVBYS8oqYD1i0IwGfZOqK2Gmh1hmZodifc7oXobbFvX+Dx1NXuud+5j4fnec6DfMBhwIAw4KPE4EEqGQ34Oj8/rD6jO+CGMOS18Tlk4oGp2RMJWZyzlA68D7wOWAa8CF5jZnMQ81wP9zewaSQOB+cABZlYdA8hEM1ubku8PgHVmdpOka4FSM7umqbL4iIRd0Na3w1HgwmfDDmTDkpDeow9Ub2mYL68QBh8S/lBDjwjPA8dCXn7abNtFR90hNyZZm0ut3bXnEbgZrJ4Db8bvfPFLsGsbKC98tweeBKNODEHh4U/DxE/C5N/ueznrakOebz4Lj38ODv4QvPYQjJsUgsvbC+DtN0INqF5eAZSObAgoySDTdwgo3imqpb+FXdth6xrYsga2roYtq8P7rWv2fr09Xgt+6Lnw5j9a9Tk0NyJhNkPkUcACM1sYC3I/cBYwJzGPAX0liXDn33VATWpGKc4CToyv7wKeA5oMIK4VOtpObtd2WPyveLT5HKyMowkU9YeRx8O7vxCCx9++Bu/6DLz6Gzj68rDc8qkw608w+Y6wTGEvGHJ4Q0AZWgn7jWr4U2db/dHhB34MZZWwbhH86ZKO2dxmFnZ4486CP5wN/YbA5lWhOWf9Yqh7Nhzt9yuDwp5tv/6Nyxq+84XPh50mhB3xhP8OAWPEcVBcEtIXvRCCR/3OcuTx+x7s8vKhajL8+fPwkd+HfA49Z898zUIt5u0F4bHuzfj6zVD2mu0N+RX2hgGjwjbk94AXboZTvgkHHBoOiv71Uxj7IfjLl1KCxRqo3py+jEX9oPf+0HtQqIEPPxZ6Dwy1sll/hBOuzkqwz2YN5BzgNDP7VHx/IXC0mV2RmKcvYbCqsUBf4DwzeyJOWwSsJwSZX5nZ7TF9g5mVJPJYb2aladZ/KXApQEVFxZGLFy/OynZ2Wbk+6qyrhRXTG3YeS/4DtTtDjaL86LDjOPAkGDIhNBU0V966uvCnrpoaAkrV1BCEanaE9fUs2bOWMvSIsLNsSSCt2RmPAlfD1rUNr7fEo8Ldr1fDtrcbllMejDoJDj8/bFefQdn6VDNTUx2O7l9/Gt54GtYtDOm99odta2MtbytxkNIGvQdC//LQnNi/HErqXw+D/hXQa789g3S6z3b+UzD7USjqG773t99oyHvUieEx8j0h73SydeCzL/nW1cHm5Q3B5e03G16vX9zQV7MHhc+r98Dw6DMoBIfe+ydeD4Q+cXph8d5Z1P8H9qEm1lwNJJsB5Fzg1JQAcpSZfT4xzznAsYRRDw8EngEON7NNkoaa2XJJg2L6583shUwDSJI3YbXCuoXwyq/DkXxh73DkM/QIGDim4QfcZ2Dihzwo7ITzmjmxr6k/4sEfbAgYi16AHRvC9MHj487jJBh+DPTo3bJ8G/uD1+6C1XMbAsryqbBqTsMfuu+QcHS9chaccFU4snvrJZh6ZyhLXkGi6WAt7GxkpOcefRN//IENz1VTYMH/wf7vCPlsj115gw5p2FkOfzcU9Wn6M20LW1bDG8/A638NTTXVm0Pn8aj3wDtOhZ6l8NRVDTujs38TjqI3LoMNS8PzxqXxEdOSR90ABcUhmNQHlrpamPMYHPelEMjnPA5r54d5C3uFo+j6z2HQuOZ/W51RTTVsWAzP3gizH4IjLoaTrg/Bel/6UNroADCXAeQY4AYzOzW+vw7AzG5MzPMEcJOZ/TO+/wdwrZm9kpLXDcAWM7tF0nzgRDNbIWkI8JyZjWmqLB5AMrC7T+G52KcQa2w9+oadScnwUE2uP7pOd9SUVxCPmGJVun5HmdxpblwG//dNOOd3cMBh8J9fhip7Uf+G5ol+ZWEHPerEsANrzyPyXdtDwEjWVOqPgpOKS9Ns48C903oPhB5pxmBLPTr8rzuguH/47N98Fpb8O1HjOqphRzr0iLbpnDULNbDXnw5Bo2oqYNB3aAgY7zg17Gh69G7dzqi+SScZVDYuC31V9a/rv+96eQUw/r/giItCx3dB0b5vZ2fQBjWFvbRRTSyXAaSA0Il+ClBF6ET/qJnNTszzS2CVmd0gaTAwFTgc2A7kmdlmSb0JNZBvm9lfJd0MvJ3oRN/PzK5uqiweQNLYtR2WvNwQMFbMBCwEiZEnhJ1VfZ9C6g+7ri500KXruNujySam1e5suiyFvRs6QEedFDoc26s/IhM7NsJfr4Xp98LRn4X3fxvyC1ufXyY75F3bQxCpP8Mo+f2MOL4hoOw/OvMO2eqtoR/hjadD4Ni8AhCUHQnvOC0EjQMO3fuzz1az0K4dsKkKXrgFZtwb2ulP/lrr8+uMct1U3IycBZC48jOAWwmn8d5hZt+TdDmAmd0maShwJzCEMIDVTWZ2t6RRhHHYIXT032tm34t5DgAeJJz6uwQ4t7lbz3sAIfYpzGjYIaXrUxh1YuhQzqRPIVNm4dz8ZIDZugZmPQRL/gWVH4Mzf5LbUx6b09ZHiK3ZIW99G956oaGGUl9D7FfW8N0V9IS/XLnnd/bgReH05rffjBfX7Qy1yoNODkHjoPeFmlOuZOPouzPpaCerpMhpAOkounwASfcjXPg8vPl3KB0RdjjJPoVBhzQc8Vcck76NPZs/7M600+ioR4jrFiX6i55v6D8pGQFbVoazzJZNbmhq3G9UQy2j4t3h4rlc66ifrdvNAwjdIIDU//HOvDWclz7jvtA5a3VherJPYeQJ0Hdw7svaWXYaHfwIEQi1y5UzEwHlnyFw9C8PpzK/4zTY/6Bcl3JvneGz7eY8gNDFAkj1tnCGVOopgavnJs4RV2iWOvScEDQGHNRx+hR8p5Fdi16AP14MlRfBtD903MDsOgUPIHSgAJLpzrN2VzhbZXeQSASLTVV75tl3aMNVruvfCv0bx38VTvmfdtkk14F0ttqd6/ByeSW6S5W84d/w42DOo/DnL4Yrav96fcMVrOvf2vP+Oz1Lwtk2I0+A/RK3RdhvVEP/Rf3O4oSrQ7/CqPf4TqO7qZq6Z7AYeUJ4XzXVfwsuK7wG0t7mPgF/+njon0gGiYLive+ZU//otV/TefqRp3MuC7wG0pGsmQ/PfD0EDqsLp1C++/MNN1hr7ZW2fuTpnMsBDyDt5Y3/CzfMk8J9fo66LDQ1SdC/bN/yTtf5PPIEDx7OuazqgjeX6WDM4OX/hXvPhV4Dwo3zzrs7XHF77p17jnLmnHOdiNdAsqmmGp78Ckz9PYw9M1zcVfEub2pyznUJHkCyZetaeODCcLuO478KJ30tfR+HNzU55zopDyDZsGoO3HdeGHjn7N/AYefmukTOOdfmPIC0tflPwUOfCneyveQpGHZkrkvknHNZ4Z3obcUsXGl+3wXhtNxLn/Xg4Zzr0rwG0hZ27Qi30Z5xHxzyYTjrf9MPIuScc12IB5B9tXkVPPAxWPZK6Cg/4aqOc+NC55zLIg8g+2LFzNBkte1tOPcuOGRSrkvknHPtxgNIa815HB65LIyN/Ym/wtAJuS6Rc861Kw8gLWUWxnB+9rtQNhHOvwf6HpDrUjnnXLvzANISu7bDY5+D1x4K40x/8KdQ2DPXpXLOuZzI6mm8kk6TNF/SAknXppneX9KfJc2QNFvSJTG9XNKzkubG9C8mlrlBUpWk6fFxRja3YbdNK+B3p8NrD8Mp34QP/8qDh3OuW8taDURSPvAL4H3AMuBVSY+b2ZzEbJ8D5pjZByUNBOZLugeoAb5iZlMl9QWmSHomseyPzeyWbJV9r5EDq6bA3efAzs2hyWrsB7K2auec6yyyWQM5ClhgZgvNrBq4HzgrZR4D+koS0AdYB9SY2QozmwpgZpuBucA+3vO8BepHDlz0Qmiu+u2psGMDfOCHHjyccy7KZh9IGbA08X4ZcHTKPD8HHgeWA32B88ysLjmDpBFAJfCfRPIVki4CJhNqKutTVy7pUuBSgIqKipaVvP4uufeeB7u2QV4BfOT3cPAHW5aPc851YdmsgaS7mi51/NxTgenAUGAC8HNJ/XZnIPUBHgKuNLNNMfmXwIFx/hXAD9Ot3MxuN7OJZjZx4MCBLS/9yBPCiIEA7/6CBw/nnEuRzQCyDChPvB9GqGkkXQI8bMECYBEwFkBSISF43GNmD9cvYGarzKw21lR+TWgqa3uLXoDFL8IJV8PUu3zQJ+ecS5HNAPIqMFrSSEk9gPMJzVVJS4BTACQNBsYAC2OfyG+BuWb2o+QCkoYk3n4YeK3NS77ohdAHcu6dPnKgc841ImsBxMxqgCuApwmd4A+a2WxJl0u6PM72HeDdkmYBfweuMbO1wLHAhcDJaU7X/YGkWZJmAicBX2rzwldNDUEj3ciBzjnnAJBZardE1zNx4kSbPHlyrovhnHOdiqQpZjaxsek+HohzzrlW8QDinHOuVTyAOOecaxUPIM4551rFA4hzzrlW6RZnYUlaAyxOJO0PrM1RcbKtq26bb1fn01W3rTtt13Aza/RWHt0igKSSNLmpU9M6s666bb5dnU9X3TbfrgbehOWcc65VPIA455xrle4aQG7PdQGyqKtum29X59NVt823K+qWfSDOOef2XXetgTjnnNtHHkCcc861SrcLIJJOkzRf0gJJ1+a6PG1F0lvxNvfTJXXqWw9LukPSakmvJdL2k/SMpDfic2kuy9gajWzXDZKq0gxb0GlIKpf0rKS5kmZL+mJM79TfWRPb1RW+s56SXpE0I27bt2J6i76zbtUHIikfeB14H2HExFeBC8xsTk4L1gYkvQVMjOOpdGqSTgC2AL83s/Ex7QfAOjO7KQb+UjO7JpflbKlGtusGYIuZ3ZLLsu2LOMjbEDObKqkvMAWYBHycTvydNbFdH6Hzf2cCepvZljj664vAF4GzacF31t1qIEcBC8xsoZlVA/cDZ+W4TC6Fmb0ArEtJPgu4K76+i/BH7lQa2a5Oz8xWmNnU+HozYQC5Mjr5d9bEdnV6cRjxLfFtYXwYLfzOulsAKQOWJt4vo4v8IAhf/t8kTZF0aa4LkwWDzWwFhD82MCjH5WlLV0iaGZu4OlUzTypJI4BK4D90oe8sZbugC3xnkvIlTQdWA8+YWYu/s+4WQJQmrau04R1rZkcApwOfi80lruP7JXAgMAFYAfwwt8VpPUl9gIeAK81sU67L01bSbFeX+M7MrNbMJgDDgKMkjW9pHt0tgCwDyhPvhwHLc1SWNmVmy+PzauARQnNdV7IqtknXt02vznF52oSZrYp/5Drg13TS7y22oz8E3GNmD8fkTv+dpduurvKd1TOzDcBzwGm08DvrbgHkVWC0pJGSegDnA4/nuEz7TFLv2MmHpN7A+4HXml6q03kcuDi+vhh4LIdlaTP1f9bow3TC7y12yP4WmGtmP0pM6tTfWWPb1UW+s4GSSuLrYuC9wDxa+J11q7OwAOIpd7cC+cAdZva9HBdpn0kaRah1ABQA93bm7ZJ0H3Ai4fbSq4BvAo8CDwIVwBLgXDPrVB3SjWzXiYSmEAPeAi6rb4PuLCQdB/wTmAXUxeTrCf0FnfY7a2K7LqDzf2eHETrJ8wkViQfN7NuSBtCC76zbBRDnnHNto7s1YTnnnGsjHkCcc861igcQ55xzreIBxDnnXKt4AHHOOdcqHkCciySNSN4ptw3z/bak9zYzzw2SvtpeZXKuLRTkugDOdXVm9o1crVtSvpnV5mr9rmvzGohzaUgaJWmapHempJ8o6TlJf5I0T9I98YplJB0p6fl4Q8unE7eEuFPSOfH1GXG5FyX9VNJfEtmPi3kvlPSFRHqBpLvizfv+JKlXzOuUWMZZ8aZ+RTH9LUnfkPQicK6kL0iaE5e/P4sfm+tmPIA4l0LSGML9jy4xs1fTzFIJXAmMA0YBx8Z7Jv0MOMfMjgTuAPa4G4CknsCvgNPN7DhgYEq+Y4FTCfdW+mbME2AMcLuZHQZsAj4b87oTOM/MDiW0JnwmkdcOMzvOzO4HrgUq4/KXt/gDca4RHkCc29NAwv1/PmZm0xuZ5xUzWxZvpjcdGEHYyY8Hnom3yP464WadSWOBhWa2KL6/L2X6E2a2Mw4KthoYHNOXmtlL8fXdwHFxfYvM7PWYfheQvAPzA4nXM4F7JH0MqGl8051rGe8DcW5PGwljxhwLzG5knp2J17WE/5GA2WZ2TBN5pxtOoLl8Ye8hByyDvLYmXn+AEFw+BPyPpEPMzAOJ22deA3FuT9WEUdgukvTRFiw3Hxgo6RgItwGXdEjKPPOAUXFwIoDzMsy7oj5fwo38Xox5jZB0UEy/EHg+dUFJeUC5mT0LXA2UAH0yXK9zTfIaiHMpzGyrpDMJzVFbzazZ25CbWXXsKP+ppP6E/9atJGoxZrZd0meBv0paC7ySYZHmAhdL+hXwBvBLM9sh6RLgj5IKCEMV3JZm2XzgSHoS9QAAAGZJREFU7lgmAT+O4z84t8/8brzOtSNJfcxsSzxz6xfAG2b241yXy7nW8CYs59rXp2Mn+2ygP+GsLOc6Ja+BOOecaxWvgTjnnGsVDyDOOedaxQOIc865VvEA4pxzrlU8gDjnnGuV/w936G8Cr6AQXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize based on sorted features\n",
    "plt.plot(range(1, 30, 2), train_scores1, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores1, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.title(\"Testing Accuracy Score Based on Sorted Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'min_samples_split': [1, 2, 3],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "grid = GridSearchCV(model5, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.905, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.907, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.886, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.889, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.883, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.904, total=   2.5s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.906, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.884, total=   2.4s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.880, total=   2.2s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.879, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.905, total=   3.7s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.902, total=   3.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.885, total=   3.4s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.880, total=   3.2s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.885, total=   3.3s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.903, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.902, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.883, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.875, total=   1.1s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.885, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.900, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.906, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.885, total=   2.4s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.882, total=   2.2s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.880, total=   2.3s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.901, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.908, total=   3.3s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.884, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.882, total=   3.4s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.880, total=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=200),\n",
       "             param_grid={'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model using sorted features\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid1 = {'min_samples_split': [1, 2, 3],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "grid1 = GridSearchCV(sorted_model5, param_grid1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=100 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=200 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/jildiz/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=1, n_estimators=300 ...........................\n",
      "[CV] . min_samples_split=1, n_estimators=300, score=nan, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.905, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.897, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.888, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.869, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=100, score=0.874, total=   0.4s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.901, total=   0.8s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.903, total=   0.9s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.894, total=   0.9s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.865, total=   1.0s\n",
      "[CV] min_samples_split=2, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=200, score=0.870, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.902, total=   1.6s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.901, total=   1.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.890, total=   1.5s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.872, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=300, score=0.874, total=   1.6s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.902, total=   0.5s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.897, total=   0.5s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.888, total=   0.4s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.869, total=   0.4s\n",
      "[CV] min_samples_split=3, n_estimators=100 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=100, score=0.871, total=   0.4s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.902, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.899, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.895, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.872, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=200 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=200, score=0.872, total=   0.8s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.904, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.901, total=   1.5s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.892, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.869, total=   1.2s\n",
      "[CV] min_samples_split=3, n_estimators=300 ...........................\n",
      "[CV]  min_samples_split=3, n_estimators=300, score=0.872, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   28.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'min_samples_split': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch using sorted features\n",
    "grid1.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.8937601423383958\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.896\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)\n",
    "print('Test Acc: %.3f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.893\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model and sorted features\n",
    "predictions1 = grid1.predict(X_test1)\n",
    "print('Test Acc: %.3f' % grid1.score(X_test1, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.75      0.78       411\n",
      "FALSE POSITIVE       0.83      0.85      0.84       484\n",
      "     CONFIRMED       0.96      1.00      0.98       853\n",
      "\n",
      "      accuracy                           0.90      1748\n",
      "     macro avg       0.87      0.86      0.87      1748\n",
      "  weighted avg       0.89      0.90      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CANDIDATE\",\"FALSE POSITIVE\",\"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.73      0.77       411\n",
      "FALSE POSITIVE       0.80      0.85      0.82       484\n",
      "     CONFIRMED       0.98      1.00      0.99       853\n",
      "\n",
      "      accuracy                           0.89      1748\n",
      "     macro avg       0.87      0.86      0.86      1748\n",
      "  weighted avg       0.89      0.89      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report with sorted features\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, predictions1,\n",
    "                            target_names=[\"CANDIDATE\",\"FALSE POSITIVE\",\"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1042627841623718, 'koi_fpflag_co'),\n",
       " (0.1005591447319951, 'koi_fpflag_nt'),\n",
       " (0.05999362312736498, 'koi_fpflag_ss'),\n",
       " (0.05809158514145868, 'koi_prad'),\n",
       " (0.05566752470422089, 'koi_model_snr'),\n",
       " (0.04020171602339959, 'koi_fpflag_ec'),\n",
       " (0.0395528606115416, 'koi_duration_err2'),\n",
       " (0.034302912424002574, 'koi_prad_err2'),\n",
       " (0.031703366812313005, 'koi_steff_err2'),\n",
       " (0.0312867265697172, 'koi_duration_err1')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can weight the features by their importance for more tuning purpose\n",
    "sorted_features=sorted(zip(model5.feature_importances_, X.columns), reverse=True)[:10]\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Importance Level')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Can be visualized in bar graph for analysis reason (feature weight)\n",
    "ax=pd.DataFrame(sorted_features).plot.bar(x=1,y=0, rot=45, title=\"Feature Importance\")\n",
    "ax.set_xlabel(\"Features Name\")\n",
    "ax.set_ylabel(\"Importance Level\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerunning Models by using top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new features based on sorted features\n",
    "X1 = df[['koi_fpflag_co', 'koi_fpflag_nt','koi_fpflag_ss', 'koi_prad','koi_model_snr','koi_fpflag_ec', 'koi_duration_err2','koi_prad_err2','koi_steff_err2','koi_duration_err1' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM.sav']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'SVM.sav'\n",
    "joblib.dump(sorted_model5, 'SVM.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
